
"""
Tushareé‡åŒ–äº¤æ˜“ç³»ç»Ÿåç«¯
éœ€è¦å®‰è£…: pip install tushare flask flask-cors pandas numpy
"""

import tushare as ts
import pandas as pd
import numpy as np
from flask import Flask, jsonify, request, send_from_directory, send_file
from flask_cors import CORS
from datetime import datetime, timedelta
import json
import os
import re
import sys
import threading
import urllib.request
import urllib.parse
import urllib.error

app = Flask(__name__)
CORS(
    app,
    resources={
        r"/api/*": {
            "origins": [
                r"^https?://localhost(:\d+)?$",
                r"^https?://127\.0\.0\.1(:\d+)?$",
                r"^https?://.*\.vercel\.app$",
                "null",
            ]
        }
    },
    supports_credentials=True,
)

def _get_app_dir():
    if getattr(sys, 'frozen', False):
        return os.path.dirname(sys.executable)
    return os.path.dirname(os.path.abspath(__file__))


APP_DIR = _get_app_dir()
RESOURCE_DIR = getattr(sys, '_MEIPASS', APP_DIR)


def _get_data_root():
    if os.environ.get('VERCEL'):
        return '/tmp'
    configured = os.getenv('QUANT_DATA_DIR')
    if configured:
        return configured
    if getattr(sys, 'frozen', False):
        base = os.getenv('LOCALAPPDATA') or APP_DIR
        return os.path.join(base, 'TushareQuantSystem')
    return APP_DIR


DATA_ROOT = _get_data_root()
try:
    os.makedirs(DATA_ROOT, exist_ok=True)
except Exception:
    pass


STOCK_LIST_CACHE_FILE = os.path.join(DATA_ROOT, 'stock_list_cache.json')
CONCEPT_LIST_CACHE_FILE = os.path.join(DATA_ROOT, 'concept_list_cache.json')
CONCEPT_MEMBERS_CACHE_DIR = os.path.join(DATA_ROOT, 'concept_members')
try:
    os.makedirs(CONCEPT_MEMBERS_CACHE_DIR, exist_ok=True)
except Exception:
    pass


LOCAL_STATE_DIR = os.path.join(DATA_ROOT, 'local_state')
try:
    os.makedirs(LOCAL_STATE_DIR, exist_ok=True)
except Exception:
    pass


_LOCAL_STATE_LOCK = threading.Lock()
_ALLOWED_LOCAL_STATE_KEYS = {
    'quant_ui_state_v1',
    'quant_kline_zoom_state_v1',
    'quant_stock_pool',
    'quant_last_session',
    'strategyConfig',
    'optimizationResults',
}


def _load_json_cache_file(file_path):
    try:
        if not os.path.exists(file_path):
            return None
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        if not isinstance(data, dict):
            return None
        cached_at = data.get('cached_at')
        items = data.get('data')
        if not cached_at or not isinstance(items, list):
            return None
        return {'cached_at': cached_at, 'data': items}
    except Exception:
        return None


def _save_json_cache_file(file_path, items):
    try:
        payload = {'cached_at': datetime.now().isoformat(), 'data': items}
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(payload, f, ensure_ascii=False)
        return True
    except Exception:
        return False


def _sanitize_local_state_filename(key):
    if not key:
        return None
    safe = re.sub(r"[^a-zA-Z0-9_.-]", "_", str(key))
    safe = safe.strip("._-")
    if not safe:
        return None
    return safe + ".json"


def _local_state_path_for_key(key):
    filename = _sanitize_local_state_filename(key)
    if not filename:
        return None
    return os.path.join(LOCAL_STATE_DIR, filename)


def _read_local_state_value(key):
    path = _local_state_path_for_key(key)
    if not path or not os.path.exists(path):
        return None
    try:
        with _LOCAL_STATE_LOCK:
            with open(path, 'r', encoding='utf-8') as f:
                data = json.load(f)
        if isinstance(data, dict) and 'value' in data:
            return data.get('value')
        return data
    except Exception:
        return None


def _write_local_state_value(key, value):
    path = _local_state_path_for_key(key)
    if not path:
        return False
    payload = {'saved_at': datetime.now().isoformat(), 'key': key, 'value': value}
    tmp_path = path + ".tmp"
    try:
        with _LOCAL_STATE_LOCK:
            with open(tmp_path, 'w', encoding='utf-8') as f:
                json.dump(payload, f, ensure_ascii=False)
            os.replace(tmp_path, path)
        return True
    except Exception:
        try:
            if os.path.exists(tmp_path):
                os.remove(tmp_path)
        except Exception:
            pass
        return False

# æ·»åŠ æ ¹è·¯å¾„è·¯ç”±ï¼Œæä¾›å‰ç«¯é¡µé¢
@app.route('/')
def index():
    """æä¾›å‰ç«¯HTMLé¡µé¢"""
    return send_from_directory(RESOURCE_DIR, 'quant_frontend.html')

# æ·»åŠ é™æ€æ–‡ä»¶è·¯ç”±
@app.route('/<path:filename>')
def static_files(filename):
    """æä¾›é™æ€æ–‡ä»¶"""
    return send_from_directory(RESOURCE_DIR, filename)

@app.route('/api/health', methods=['GET'])
def api_health():
    return jsonify({
        'success': True,
        'token_present': bool(TUSHARE_TOKEN),
        'token_source': TUSHARE_TOKEN_SOURCE,
        'pro_initialized': pro is not None,
        'pro_init_error': _PRO_INIT_ERROR,
        'data_root': DATA_ROOT
    })

def _load_tushare_token():
    candidates = [
        'TUSHARE_TOKEN',
        'TS_TOKEN',
        'TUSHARETOKEN',
        'TU_SHARE_TOKEN',
    ]
    for name in candidates:
        env_token = os.getenv(name)
        if env_token and env_token.strip():
            return env_token.strip(), f'env:{name}'
    token_file = os.path.join(DATA_ROOT, 'tushare_token.txt')
    try:
        if os.path.exists(token_file):
            with open(token_file, 'r', encoding='utf-8') as f:
                return ((f.read() or '').strip(), f'file:{token_file}')
    except Exception:
        return '', ''
    return '', ''


TUSHARE_TOKEN = ''
TUSHARE_TOKEN_SOURCE = ''
_PRO_INIT_ERROR = ''
_PRO_INIT_LOCK = threading.Lock()


def _is_writable_dir(path):
    if not path or not os.path.isdir(path):
        return False
    probe = os.path.join(path, '.probe_write')
    try:
        with open(probe, 'w', encoding='utf-8') as f:
            f.write('')
        os.remove(probe)
        return True
    except Exception:
        return False


def _init_tushare_pro():
    global TUSHARE_TOKEN, TUSHARE_TOKEN_SOURCE, pro, _PRO_INIT_ERROR
    token, source = _load_tushare_token()
    TUSHARE_TOKEN = token
    TUSHARE_TOKEN_SOURCE = source

    print("æ­£åœ¨åˆå§‹åŒ–Tushare...")
    try:
        if os.environ.get('VERCEL') and os.name != 'nt':
            fallback_home = DATA_ROOT or '/tmp'
            try:
                os.makedirs(fallback_home, exist_ok=True)
            except Exception:
                pass
            current_home = os.environ.get('HOME')
            if not _is_writable_dir(current_home):
                os.environ['HOME'] = fallback_home
            current_userprofile = os.environ.get('USERPROFILE')
            if not _is_writable_dir(current_userprofile):
                os.environ['USERPROFILE'] = fallback_home
            os.environ.setdefault('XDG_CACHE_HOME', fallback_home)
            os.environ.setdefault('XDG_CONFIG_HOME', fallback_home)

        if not TUSHARE_TOKEN:
            raise RuntimeError("æœªé…ç½®Tushare Tokenï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡TUSHARE_TOKEN/TS_TOKENæˆ–åœ¨æ•°æ®ç›®å½•æ”¾ç½®tushare_token.txt")
        try:
            ts.set_token(TUSHARE_TOKEN)
        except Exception:
            pass
        pro = ts.pro_api(TUSHARE_TOKEN)
        _PRO_INIT_ERROR = ''
        print("âœ“ Tushareåˆå§‹åŒ–æˆåŠŸ")
        return pro
    except Exception as e:
        _PRO_INIT_ERROR = str(e)
        print(f"âœ— Tushareåˆå§‹åŒ–å¤±è´¥: {e}")
        pro = None
        return None


def _get_pro():
    global pro
    if pro is not None:
        return pro
    with _PRO_INIT_LOCK:
        if pro is not None:
            return pro
        return _init_tushare_pro()

_init_tushare_pro()


INDEX_CONSTITUENTS_CACHE_FILE = os.path.join(DATA_ROOT, 'index_constituents_cache.json')


def _load_index_cache_file():
    try:
        if not os.path.exists(INDEX_CONSTITUENTS_CACHE_FILE):
            return {}
        with open(INDEX_CONSTITUENTS_CACHE_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data if isinstance(data, dict) else {}
    except Exception as e:
        print(f"è¯»å–æŒ‡æ•°æˆåˆ†ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")
        return {}


def _save_index_cache_file(cache_dict):
    try:
        with open(INDEX_CONSTITUENTS_CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(cache_dict, f, ensure_ascii=False)
    except Exception as e:
        print(f"å†™å…¥æŒ‡æ•°æˆåˆ†ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")


def _get_index_code_numeric(index_code):
    if not index_code:
        return None
    s = str(index_code).strip().upper()
    return s.split('.')[0] if '.' in s else s


def _fetch_index_constituents_from_sina(index_code):
    index_id = _get_index_code_numeric(index_code)
    if not index_id or not re.fullmatch(r"\d{6}", index_id):
        return []

    url = f"http://vip.stock.finance.sina.com.cn/corp/go.php/vII_NewestComponent/indexid/{index_id}.phtml"
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'
    }
    req = urllib.request.Request(url, headers=headers)

    try:
        with urllib.request.urlopen(req, timeout=6) as resp:
            raw = resp.read()
        html = raw.decode('gbk', errors='ignore')
    except Exception as e:
        print(f"ä»æ–°æµªæŠ“å–æŒ‡æ•°æˆåˆ†å¤±è´¥: {index_code}: {e}")
        return []

    matches = re.findall(r"\b(sh|sz)(\d{6})\b", html, flags=re.IGNORECASE)
    if not matches:
        return []

    codes = []
    seen = set()
    for market, code in matches:
        ts_code = f"{code}.{'SH' if market.lower() == 'sh' else 'SZ'}"
        if ts_code in seen:
            continue
        seen.add(ts_code)
        codes.append({'ts_code': ts_code, 'name': ts_code})

    return codes


def _fetch_index_constituents_from_legulegu(index_code):
    index_id = str(index_code).strip().upper()
    if not index_id:
        return []
    if '.' not in index_id:
        index_id = f"{index_id}.SH"

    url = f"https://legulegu.com/stockdata/index-basic-composition?indexCode={index_id}"
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'
    }
    req = urllib.request.Request(url, headers=headers)

    try:
        with urllib.request.urlopen(req, timeout=10) as resp:
            raw = resp.read()
        html = raw.decode('utf-8', errors='ignore')
    except Exception as e:
        print(f"ä»ä¹å’•ä¹è‚¡æŠ“å–æŒ‡æ•°æˆåˆ†å¤±è´¥: {index_code}: {e}")
        return []

    expected_count = None
    index_numeric = _get_index_code_numeric(index_id)
    if index_numeric == '000016':
        expected_count = 50
    elif index_numeric == '000300':
        expected_count = 300

    codes = re.findall(r"\b\d{6}\.(?:SH|SZ)\b", html, flags=re.IGNORECASE)
    if not codes:
        return []

    ordered = []
    seen = set()
    skip_code = index_id.upper()
    for c in codes:
        c = c.upper()
        if c == skip_code:
            continue
        if c in seen:
            continue
        seen.add(c)
        ordered.append(c)

    if expected_count and len(ordered) >= expected_count:
        ordered = ordered[:expected_count]

    return [{'ts_code': c, 'name': c} for c in ordered]

class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨ï¼ˆæ”¯æŒæœ¬åœ°CSVæŒä¹…åŒ–ï¼‰"""
    
    def __init__(self):
        self.stock_cache = {}
        self.params_cache = {}
        self.data_dir = os.path.join(DATA_ROOT, 'data')
        if not os.path.exists(self.data_dir):
            try:
                os.makedirs(self.data_dir)
            except Exception as e:
                print(f"åˆ›å»ºæ•°æ®ç›®å½•å¤±è´¥: {e}")
    
    def get_stock_data(self, ts_code, start_date, end_date, freq='D'):
        """è·å–è‚¡ç¥¨æ•°æ®ï¼ˆä¼˜å…ˆè¯»å–æœ¬åœ°CSVï¼Œæ”¯æŒå¢é‡æ›´æ–°ï¼‰
        
        Args:
            ts_code: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            freq: å‘¨æœŸï¼Œ'D'=æ—¥çº¿, 'W'=å‘¨çº¿, 'M'=æœˆçº¿
        """
        # ä¸åŒå‘¨æœŸä½¿ç”¨ä¸åŒçš„ç¼“å­˜æ–‡ä»¶
        freq_suffix = '' if freq == 'D' else f'_{freq}'
        file_path = os.path.join(self.data_dir, f"{ts_code}{freq_suffix}.csv")
        local_df = None
        
        # 1. å°è¯•è¯»å–æœ¬åœ°æ–‡ä»¶
        if os.path.exists(file_path):
            try:
                # æŒ‡å®šdtypeä»¥é˜²æ­¢æ•°æ®ç±»å‹é”™è¯¯
                local_df = pd.read_csv(file_path, dtype={'date': str})
                if 'date' in local_df.columns:
                    local_df = local_df.sort_values('date').drop_duplicates(subset=['date']).reset_index(drop=True)
                else:
                    print(f"[æ•°æ®æŸå] {file_path} ç¼ºå°‘dateåˆ—")
                    local_df = None
            except Exception as e:
                print(f"[è¯»å–ç¼“å­˜å¤±è´¥] {file_path}: {e}")
                local_df = None
        
        # 2. æ£€æŸ¥å¹¶è¡¥å……æ•°æ®
        if local_df is not None and not local_df.empty:
            local_min = local_df['date'].min()
            local_max = local_df['date'].max()
            data_changed = False
            
            # A. å‘å‰è¡¥å……ï¼ˆè¯·æ±‚å¼€å§‹æ—¶é—´æ—©äºæœ¬åœ°æœ€æ—©æ—¶é—´ï¼‰
            if start_date < local_min:
                pre_end_date = (datetime.strptime(local_min, '%Y-%m-%d') - timedelta(days=1)).strftime('%Y-%m-%d')
                if start_date <= pre_end_date:
                    print(f"[å‘å‰è¡¥å……] {ts_code} {freq}: {start_date} ~ {pre_end_date}")
                    pre_data = TushareDataFetcher.get_stock_data(ts_code, start_date, pre_end_date, freq)
                    if pre_data:
                        pre_df = pd.DataFrame(pre_data)
                        local_df = pd.concat([pre_df, local_df]).drop_duplicates(subset=['date']).sort_values('date').reset_index(drop=True)
                        data_changed = True
            
            # B. å‘åè¡¥å……ï¼ˆè¯·æ±‚ç»“æŸæ—¶é—´æ™šäºæœ¬åœ°æœ€æ–°æ—¶é—´ï¼‰
            if end_date > local_max:
                inc_start_date = (datetime.strptime(local_max, '%Y-%m-%d') + timedelta(days=1)).strftime('%Y-%m-%d')
                if inc_start_date <= end_date:
                    print(f"[å¢é‡æ›´æ–°] {ts_code} {freq}: {inc_start_date} ~ {end_date}")
                    inc_data = TushareDataFetcher.get_stock_data(ts_code, inc_start_date, end_date, freq)
                    if inc_data:
                        inc_df = pd.DataFrame(inc_data)
                        local_df = pd.concat([local_df, inc_df]).drop_duplicates(subset=['date']).sort_values('date').reset_index(drop=True)
                        data_changed = True
            
            # å¦‚æœæœ‰æ›´æ–°ï¼Œä¿å­˜å›æ–‡ä»¶
            if data_changed:
                try:
                    local_df.to_csv(file_path, index=False)
                    print(f"[æŒä¹…åŒ–] å·²æ›´æ–° {file_path}, æ¡æ•°: {len(local_df)}")
                except Exception as e:
                    print(f"[ä¿å­˜å¤±è´¥] {e}")

            # åªæœ‰æ—¥çº¿æ•°æ®æ‰è¡¥å…… pe/pb
            if freq == 'D':
                try:
                    need_fill = (
                        pro is not None and
                        (('pe' not in local_df.columns) or local_df['pe'].isna().all() or
                         ('pb' not in local_df.columns) or local_df['pb'].isna().all())
                    )
                    if need_fill:
                        df_basic = pro.daily_basic(
                            ts_code=ts_code,
                            start_date=start_date.replace('-', ''),
                            end_date=end_date.replace('-', ''),
                            fields='trade_date,pe,pb'
                        )
                        if df_basic is not None and not df_basic.empty:
                            df_basic = df_basic.rename(columns={'trade_date': 'date'})
                            df_basic['date'] = pd.to_datetime(df_basic['date']).dt.strftime('%Y-%m-%d')
                            if 'pe' not in local_df.columns:
                                local_df['pe'] = None
                            if 'pb' not in local_df.columns:
                                local_df['pb'] = None
                            merged = local_df.merge(df_basic[['date', 'pe', 'pb']], on='date', how='left', suffixes=('', '_new'))
                            if 'pe_new' in merged.columns:
                                merged['pe'] = merged['pe'].fillna(merged['pe_new'])
                                merged.drop(columns=['pe_new'], inplace=True)
                            if 'pb_new' in merged.columns:
                                merged['pb'] = merged['pb'].fillna(merged['pb_new'])
                                merged.drop(columns=['pb_new'], inplace=True)
                            local_df = merged
                            local_df.to_csv(file_path, index=False)
                except Exception as e:
                    print(f"è¡¥é½pe/pbå¤±è´¥: {e}")

        else:
            # 3. æœ¬åœ°æ— æ•°æ®ï¼Œå…¨é‡è·å–
            print(f"[æœ¬åœ°æ— ç¼“å­˜] å…¨é‡è·å– {ts_code} {freq}: {start_date} ~ {end_date}")
            data = TushareDataFetcher.get_stock_data(ts_code, start_date, end_date, freq)
            if data:
                local_df = pd.DataFrame(data)
                try:
                    local_df.to_csv(file_path, index=False)
                    print(f"[æŒä¹…åŒ–] å·²ä¿å­˜ {file_path}, æ¡æ•°: {len(local_df)}")
                except Exception as e:
                    print(f"[ä¿å­˜å¤±è´¥] {e}")
            else:
                # å°è¯•å¤‡ç”¨æ•°æ®æºï¼ˆä»…æ—¥çº¿ï¼‰
                if freq == 'D':
                    try:
                        print("å°è¯•ä½¿ç”¨å¤‡ç”¨æ•°æ®æº(Eastmoney)...")
                        data = EastmoneyDataFetcher.get_stock_data(ts_code, start_date, end_date)
                        if data:
                            local_df = pd.DataFrame(data)
                            local_df.to_csv(file_path, index=False)
                            print(f"[æŒä¹…åŒ–] (å¤‡ç”¨æº) å·²ä¿å­˜ {file_path}")
                    except Exception as e:
                        print(f"å¤‡ç”¨æºè·å–å¤±è´¥: {e}")

        # 4. è¿”å›è¯·æ±‚åŒºé—´çš„æ•°æ®
        if local_df is not None and not local_df.empty:
            # è¿‡æ»¤æ—¶é—´åŒºé—´
            mask = (local_df['date'] >= start_date) & (local_df['date'] <= end_date)
            result_df = local_df.loc[mask]
            
            if result_df.empty:
                return []
            
            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨ï¼Œå¹¶å°†NaNè½¬ä¸ºNone
            return result_df.where(pd.notnull(result_df), None).to_dict('records')
            
        return []
    
    def get(self, cache_type, key):
        """è·å–ç¼“å­˜"""
        if cache_type == 'params':
            return self.params_cache.get(key)
        return None
    
    def set(self, cache_type, key, data):
        """è®¾ç½®ç¼“å­˜"""
        if cache_type == 'params':
            self.params_cache[key] = {
                'meta': {
                    'cached_at': datetime.now().isoformat()
                },
                'data': data
            }

# åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
cache_manager = CacheManager()

class TushareDataFetcher:
    """Tushareæ•°æ®è·å–ç±»"""
    
    @staticmethod
    def get_stock_data(ts_code, start_date, end_date, freq='D'):
        """è·å–è‚¡ç¥¨æ•°æ®ï¼Œæ”¯æŒæ—¥çº¿/å‘¨çº¿/æœˆçº¿
        
        Args:
            ts_code: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            freq: å‘¨æœŸï¼Œ'D'=æ—¥çº¿, 'W'=å‘¨çº¿, 'M'=æœˆçº¿
        """
        if pro is None:
            print("âœ— Tushare APIæœªåˆå§‹åŒ–")
            return None
            
        try:
            print(f"æ­£åœ¨è·å– {ts_code} ä» {start_date} åˆ° {end_date} çš„{freq}çº¿æ•°æ®...")
            
            # æ ¹æ®å‘¨æœŸé€‰æ‹©æ¥å£
            if freq == 'W':
                df = pro.weekly(
                    ts_code=ts_code,
                    start_date=start_date.replace('-', ''),
                    end_date=end_date.replace('-', '')
                )
            elif freq == 'M':
                df = pro.monthly(
                    ts_code=ts_code,
                    start_date=start_date.replace('-', ''),
                    end_date=end_date.replace('-', '')
                )
            else:  # é»˜è®¤æ—¥çº¿
                df = pro.daily(
                    ts_code=ts_code,
                    start_date=start_date.replace('-', ''),
                    end_date=end_date.replace('-', '')
                )
            
            print(f"è·å–åˆ°åŸå§‹æ•°æ®: {len(df) if df is not None else 'None'} æ¡")
            
            if df is None or df.empty:
                print("æ•°æ®ä¸ºç©ºæˆ–None")
                return None
            
            # æŒ‰æ—¥æœŸå‡åºæ’åˆ—
            df = df.sort_values('trade_date').reset_index(drop=True)
            
            # é‡å‘½ååˆ—
            df = df.rename(columns={
                'trade_date': 'date',
                'vol': 'volume',
                'pct_chg': 'pctChange',
                'change': 'priceChange'
            })
            
            # æ ¼å¼åŒ–æ—¥æœŸ
            df['date'] = pd.to_datetime(df['date']).dt.strftime('%Y-%m-%d')
            
            # è·å–æ¢æ‰‹ç‡æ•°æ®ï¼ˆå¯é€‰ï¼Œå› ä¸ºå¯èƒ½éœ€è¦æƒé™ï¼‰
            try:
                df_basic = pro.daily_basic(
                    ts_code=ts_code,
                    start_date=start_date.replace('-', ''),
                    end_date=end_date.replace('-', ''),
                    fields='trade_date,turnover_rate,pe,pb'
                )
                
                if df_basic is not None and not df_basic.empty:
                    df_basic = df_basic.rename(columns={
                        'trade_date': 'date',
                        'turnover_rate': 'turnover'
                    })
                    df_basic['date'] = pd.to_datetime(df_basic['date']).dt.strftime('%Y-%m-%d')
                    df = df.merge(df_basic[['date', 'turnover', 'pe', 'pb']], on='date', how='left')
            except Exception as e:
                print(f"è·å–æ¢æ‰‹ç‡æ•°æ®å¤±è´¥ï¼ˆå¯èƒ½éœ€è¦æ›´é«˜æƒé™ï¼‰: {e}")
                # æ·»åŠ ç©ºåˆ—ä½œä¸ºå ä½ç¬¦
                df['turnover'] = None
                df['pe'] = None
                df['pb'] = None

            if 'turnover' not in df.columns or df['turnover'].isna().all():
                float_share = None
                try:
                    df_share = pro.stock_basic(ts_code=ts_code, fields='ts_code,float_share')
                    if df_share is not None and not df_share.empty:
                        float_share = df_share.iloc[0].get('float_share')
                except Exception:
                    float_share = None
                
                if float_share and isinstance(float_share, (int, float)) and float_share > 0:
                    turnover_est = df['volume'] / (float_share * 100)
                    df['turnover'] = turnover_est.clip(lower=0, upper=100)

            try:
                if 'turnover' not in df.columns or df['turnover'].isna().all():
                    em = EastmoneyDataFetcher.get_stock_data(ts_code, start_date, end_date)
                    em_by_date = {row.get('date'): row for row in (em or []) if isinstance(row, dict) and row.get('date')}
                    if em_by_date:
                        df['turnover'] = df['date'].map(lambda d: em_by_date.get(d, {}).get('turnover'))
                        if 'amount' in df.columns:
                            df['amount'] = df['amount'].fillna(df['date'].map(lambda d: em_by_date.get(d, {}).get('amount')))
            except Exception as e:
                print(f"ä»ä¸œæ–¹è´¢å¯Œè¡¥å…¨æ¢æ‰‹ç‡å¤±è´¥: {e}")

            try:
                df_adj = pro.adj_factor(
                    ts_code=ts_code,
                    start_date=start_date.replace('-', ''),
                    end_date=end_date.replace('-', '')
                )
                if df_adj is not None and not df_adj.empty:
                    df_adj = df_adj.rename(columns={'trade_date': 'date'})
                    df_adj['date'] = pd.to_datetime(df_adj['date']).dt.strftime('%Y-%m-%d')
                    df_adj = df_adj.sort_values('date').reset_index(drop=True)
                    latest_adj = df_adj['adj_factor'].iloc[-1]
                    df = df.merge(df_adj[['date', 'adj_factor']], on='date', how='left')
                    df['adj_factor'] = df['adj_factor'].ffill()
                    if pd.notna(latest_adj) and latest_adj > 0:
                        factor = df['adj_factor'] / latest_adj
                        for col in ['open', 'high', 'low', 'close']:
                            if col in df.columns:
                                df[col] = df[col] * factor
            except Exception as e:
                print(f"è·å–å¤æƒå› å­å¤±è´¥: {e}")
            
            return df.to_dict('records')
            
        except Exception as e:
            print(f"è·å–æ•°æ®é”™è¯¯: {e}")
            return None
    
    @staticmethod
    def get_stock_list():
        """è·å–è‚¡ç¥¨åˆ—è¡¨"""
        if pro is None:
            print("âœ— Tushare APIæœªåˆå§‹åŒ–ï¼Œä½¿ç”¨é»˜è®¤è‚¡ç¥¨åˆ—è¡¨")
            return [
                {'ts_code': '000001.SZ', 'symbol': '000001', 'name': 'å¹³å®‰é“¶è¡Œ', 'industry': 'é“¶è¡Œ', 'market': 'ä¸»æ¿'},
                {'ts_code': '000002.SZ', 'symbol': '000002', 'name': 'ä¸‡ç§‘A', 'industry': 'æˆ¿åœ°äº§', 'market': 'ä¸»æ¿'},
                {'ts_code': '600519.SH', 'symbol': '600519', 'name': 'è´µå·èŒ…å°', 'industry': 'ç™½é…’', 'market': 'ä¸»æ¿'},
                {'ts_code': '000858.SZ', 'symbol': '000858', 'name': 'äº”ç²®æ¶²', 'industry': 'ç™½é…’', 'market': 'ä¸»æ¿'},
                {'ts_code': '601318.SH', 'symbol': '601318', 'name': 'ä¸­å›½å¹³å®‰', 'industry': 'ä¿é™©', 'market': 'ä¸»æ¿'}
            ]
        try:
            df = pro.stock_basic(
                exchange='',
                list_status='L',
                fields='ts_code,symbol,name,industry,market'
            )
            return df.to_dict('records') if df is not None else []
        except Exception as e:
            print(f"è·å–è‚¡ç¥¨åˆ—è¡¨é”™è¯¯: {e}")
            return [
                {'ts_code': '000001.SZ', 'symbol': '000001', 'name': 'å¹³å®‰é“¶è¡Œ', 'industry': 'é“¶è¡Œ', 'market': 'ä¸»æ¿'},
                {'ts_code': '000002.SZ', 'symbol': '000002', 'name': 'ä¸‡ç§‘A', 'industry': 'æˆ¿åœ°äº§', 'market': 'ä¸»æ¿'},
                {'ts_code': '600519.SH', 'symbol': '600519', 'name': 'è´µå·èŒ…å°', 'industry': 'ç™½é…’', 'market': 'ä¸»æ¿'},
                {'ts_code': '000858.SZ', 'symbol': '000858', 'name': 'äº”ç²®æ¶²', 'industry': 'ç™½é…’', 'market': 'ä¸»æ¿'},
                {'ts_code': '601318.SH', 'symbol': '601318', 'name': 'ä¸­å›½å¹³å®‰', 'industry': 'ä¿é™©', 'market': 'ä¸»æ¿'},
                {'ts_code': '600036.SH', 'symbol': '600036', 'name': 'æ‹›å•†é“¶è¡Œ', 'industry': 'é“¶è¡Œ', 'market': 'ä¸»æ¿'},
                {'ts_code': '000333.SZ', 'symbol': '000333', 'name': 'ç¾çš„é›†å›¢', 'industry': 'å®¶ç”µ', 'market': 'ä¸»æ¿'},
                {'ts_code': '002415.SZ', 'symbol': '002415', 'name': 'æµ·åº·å¨è§†', 'industry': 'è½¯ä»¶æœåŠ¡', 'market': 'ä¸­å°æ¿'},
                {'ts_code': '300750.SZ', 'symbol': '300750', 'name': 'å®å¾·æ—¶ä»£', 'industry': 'ç”µæ°”è®¾å¤‡', 'market': 'åˆ›ä¸šæ¿'},
                {'ts_code': '600309.SH', 'symbol': '600309', 'name': 'ä¸‡ååŒ–å­¦', 'industry': 'åŒ–å·¥', 'market': 'ä¸»æ¿'}
            ]
    
    @staticmethod
    def get_index_weights(index_code='000300.SH'):
        """è·å–æŒ‡æ•°æˆåˆ†è‚¡"""
        file_cache = _load_index_cache_file()

        cached_item = file_cache.get(index_code)
        if isinstance(cached_item, dict) and isinstance(cached_item.get('data'), list):
            try:
                cached_at = datetime.fromisoformat(cached_item.get('cached_at'))
                if (datetime.now() - cached_at).days < 30:
                    return cached_item['data']
            except Exception:
                pass

        if pro is None:
            data = _fetch_index_constituents_from_legulegu(index_code)
            if not data:
                data = _fetch_index_constituents_from_sina(index_code)
            if data:
                file_cache[index_code] = {'cached_at': datetime.now().isoformat(), 'data': data}
                _save_index_cache_file(file_cache)
            return data
        try:
            # è·å–æŒ‡æ•°æˆåˆ†è‚¡
            df = pro.index_weight(index_code=index_code, start_date='20230101', end_date=datetime.now().strftime('%Y%m%d'))
            if df is None or df.empty:
                return []
            
            # åªå–æœ€æ–°çš„æˆåˆ†è‚¡
            latest_date = df['trade_date'].max()
            df = df[df['trade_date'] == latest_date]
            
            # è·å–è‚¡ç¥¨åç§°
            codes = df['con_code'].tolist()
            # åˆ†æ‰¹è·å–åç§°
            all_stocks = []
            for i in range(0, len(codes), 100):
                batch_codes = codes[i:i+100]
                df_basic = pro.stock_basic(ts_code=','.join(batch_codes), fields='ts_code,symbol,name,industry')
                if df_basic is not None:
                    all_stocks.extend(df_basic.to_dict('records'))
            
            return all_stocks
        except Exception as e:
            print(f"è·å–æŒ‡æ•°æˆåˆ†è‚¡é”™è¯¯: {e}")
            data = _fetch_index_constituents_from_legulegu(index_code)
            if not data:
                data = _fetch_index_constituents_from_sina(index_code)
            if data:
                file_cache[index_code] = {'cached_at': datetime.now().isoformat(), 'data': data}
                _save_index_cache_file(file_cache)
                return data

            if isinstance(cached_item, dict) and isinstance(cached_item.get('data'), list):
                return cached_item['data']

            return []

    @staticmethod
    def search_stock(keyword):
        """æœç´¢è‚¡ç¥¨"""
        try:
            df = pro.stock_basic(
                exchange='',
                list_status='L',
                fields='ts_code,symbol,name,industry'
            )
            # æ¨¡ç³Šæœç´¢
            mask = (
                df['ts_code'].str.contains(keyword, case=False, na=False) |
                df['name'].str.contains(keyword, case=False, na=False) |
                df['symbol'].str.contains(keyword, case=False, na=False)
            )
            return df[mask].head(20).to_dict('records')
        except Exception as e:
            print(f"æœç´¢è‚¡ç¥¨é”™è¯¯: {e}")
            return []

    @staticmethod
    def gen_mock_data(ts_code, start_date, end_date):
        """ç”Ÿæˆæ¨¡æ‹Ÿè‚¡ç¥¨æ•°æ®"""
        print(f"æ­£åœ¨ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ® {ts_code} ä» {start_date} åˆ° {end_date}")
        
        # è§£ææ—¥æœŸ
        start = datetime.strptime(start_date, '%Y-%m-%d')
        end = datetime.strptime(end_date, '%Y-%m-%d')
        
        # ç”Ÿæˆæ—¥æœŸåºåˆ—ï¼ˆåªåŒ…å«å·¥ä½œæ—¥ï¼‰
        dates = []
        current_date = start
        while current_date <= end:
            if current_date.weekday() < 5:  # åªåŒ…å«å·¥ä½œæ—¥
                dates.append(current_date.strftime('%Y-%m-%d'))
            current_date += timedelta(days=1)
        
        if not dates:
            print("âŒ æ²¡æœ‰ç”Ÿæˆä»»ä½•æ—¥æœŸ")
            return []
        
        print(f"ğŸ“… ç”Ÿæˆäº† {len(dates)} ä¸ªäº¤æ˜“æ—¥")
        
        # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        data = []
        base_price = 10 + np.random.random() * 40  # éšæœºåŸºç¡€ä»·æ ¼ 10-50
        
        for i, date in enumerate(dates):
            # ä»·æ ¼æ³¢åŠ¨
            daily_change = (np.random.random() - 0.48) * 0.1  # ç•¥å¾®ä¸Šæ¶¨è¶‹åŠ¿
            if i == 0:
                open_price = base_price
            else:
                prev_close = data[i-1]['close']
                open_price = prev_close * (1 + np.random.random() * 0.02 - 0.01)  # Â±1% å¼€ç›˜æ³¢åŠ¨
            
            close_price = open_price * (1 + daily_change)
            
            # ç¡®å®šå½“æ—¥ä»·æ ¼èŒƒå›´ï¼ŒåŸºäºå¼€ç›˜ä»·å’Œæ”¶ç›˜ä»·
            higher_price = max(open_price, close_price)
            lower_price = min(open_price, close_price)
            
            # è®¡ç®—æœ€é«˜ä»·å’Œæœ€ä½ä»·
            high_price = higher_price * (1 + np.random.random() * 0.03)  # æœ€é«˜ä»·æ ¼
            low_price = lower_price * (1 - np.random.random() * 0.03)   # æœ€ä½ä»·æ ¼
            
            # ç¡®ä¿é«˜ä½ä»·æ ¼åˆç†
            high_price = max(high_price, higher_price)
            low_price = min(low_price, lower_price)
            low_price = max(0, low_price)  # ç¡®ä¿æœ€ä½ä»·éè´Ÿ
            
            volume = int(np.random.random() * 10000000) + 1000000  # 100ä¸‡åˆ°1100ä¸‡è‚¡
            
            row = {
                'date': date,
                'open': round(open_price, 2),
                'high': round(high_price, 2),
                'low': round(low_price, 2),
                'close': round(close_price, 2),
                'volume': volume,
                'pctChange': round((close_price - open_price) / open_price * 100, 2),
                'priceChange': round(close_price - open_price, 2),
                'turnover': round(np.random.random() * 5, 2),  # æ¢æ‰‹ç‡ 0-5%
                'pe': round(15 + np.random.random() * 20, 2),  # å¸‚ç›ˆç‡ 15-35
                'pb': round(1 + np.random.random() * 3, 2)     # å¸‚å‡€ç‡ 1-4
            }
            
            data.append(row)
        
        print(f"ç”Ÿæˆäº† {len(data)} æ¡æ¨¡æ‹Ÿæ•°æ®")
        return data


def _eastmoney_secid(ts_code):
    if not ts_code:
        return None
    s = str(ts_code).strip().upper()
    if '.' in s:
        symbol, exch = s.split('.', 1)
    else:
        symbol = re.sub(r"\D", "", s)
        exch = 'SH' if symbol.startswith('6') else 'SZ'
    symbol = re.sub(r"\D", "", symbol)
    if not re.fullmatch(r"\d{6}", symbol):
        return None
    market = '1' if exch == 'SH' else '0'
    return f"{market}.{symbol}"


class EastmoneyDataFetcher:
    @staticmethod
    def get_stock_data(ts_code, start_date, end_date):
        secid = _eastmoney_secid(ts_code)
        if not secid:
            return None

        beg = start_date.replace('-', '')
        end = end_date.replace('-', '')
        params = {
            'secid': secid,
            'klt': 101,
            'fqt': 1,
            'beg': beg,
            'end': end,
            'fields1': 'f1,f2,f3,f4,f5,f6',
            'fields2': 'f51,f52,f53,f54,f55,f56,f57,f58,f59,f60,f61'
        }
        url = 'https://push2his.eastmoney.com/api/qt/stock/kline/get?' + urllib.parse.urlencode(params)
        req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0', 'Referer': 'https://quote.eastmoney.com/'})
        with urllib.request.urlopen(req, timeout=12) as resp:
            payload = json.loads(resp.read().decode('utf-8'))

        data = (payload or {}).get('data') or {}
        klines = data.get('klines') or []
        out = []
        for row in klines:
            if not isinstance(row, str):
                continue
            parts = row.split(',')
            if len(parts) < 11:
                continue
            date = parts[0]
            try:
                out.append({
                    'date': date,
                    'open': float(parts[1]),
                    'close': float(parts[2]),
                    'high': float(parts[3]),
                    'low': float(parts[4]),
                    'volume': float(parts[5]),
                    'amount': float(parts[6]),
                    'pctChange': float(parts[8]),
                    'priceChange': float(parts[9]),
                    'turnover': float(parts[10]),
                    'ts_code': ts_code
                })
            except Exception:
                continue
        return out


class TechnicalIndicators:
    """æŠ€æœ¯æŒ‡æ ‡è®¡ç®—ç±»"""
    
    @staticmethod
    def calculate_all(data):
        """è®¡ç®—æ‰€æœ‰æŠ€æœ¯æŒ‡æ ‡"""
        df = pd.DataFrame(data)
        
        # ç§»åŠ¨å¹³å‡çº¿
        for period in [5, 10, 20, 60]:
            df[f'ma{period}'] = df['close'].rolling(window=period).mean()
        
        # æˆäº¤é‡å‡çº¿
        for period in [5, 10, 20]:
            df[f'volMa{period}'] = df['volume'].rolling(window=period).mean()
        
        # RSI
        delta = df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['rsi'] = 100 - (100 / (1 + rs))
        
        # MACD
        exp1 = df['close'].ewm(span=12, adjust=False).mean()
        exp2 = df['close'].ewm(span=26, adjust=False).mean()
        df['dif'] = exp1 - exp2
        df['dea'] = df['dif'].ewm(span=9, adjust=False).mean()
        df['macd'] = (df['dif'] - df['dea']) * 2
        
        # å¸ƒæ—å¸¦
        df['bollMid'] = df['close'].rolling(window=20).mean()
        df['bollStd'] = df['close'].rolling(window=20).std()
        df['bollUp'] = df['bollMid'] + 2 * df['bollStd']
        df['bollDown'] = df['bollMid'] - 2 * df['bollStd']
        
        # ATR
        df['tr'] = np.maximum(
            df['high'] - df['low'],
            np.maximum(
                abs(df['high'] - df['close'].shift(1)),
                abs(df['low'] - df['close'].shift(1))
            )
        )
        df['atr'] = df['tr'].rolling(window=20).mean()
        
        # Næ—¥æœ€é«˜æœ€ä½
        for period in [10, 20]:
            df[f'high{period}'] = df['high'].rolling(window=period).max()
            df[f'low{period}'] = df['low'].rolling(window=period).min()
        
        # KDJ
        low_min = df['low'].rolling(window=9).min()
        high_max = df['high'].rolling(window=9).max()
        rsv = (df['close'] - low_min) / (high_max - low_min) * 100
        df['k'] = rsv.ewm(com=2, adjust=False).mean()
        df['d'] = df['k'].ewm(com=2, adjust=False).mean()
        df['j'] = 3 * df['k'] - 2 * df['d']
        
        # æ›¿æ¢NaNä¸ºNone
        df = df.replace({np.nan: None})
        
        return df.to_dict('records')


class CrossStockParamOptimizer:
    """è·¨è‚¡ç¥¨å‚æ•°ä¼˜åŒ–å™¨ - è§£å†³å•è‚¡ç¥¨å‚æ•°å±€é™æ€§é—®é¢˜"""
    
    # é¢„è®¾çš„é€šç”¨å‚æ•°æ¨¡æ¿ï¼ˆåŸºäºå¤§é‡è‚¡ç¥¨å›æµ‹ä¼˜åŒ–å¾—å‡ºï¼‰
    UNIVERSAL_PARAMS = {
        'deep_fusion': {
            'mlScoreThreshold': 55,
            'minConfirmations': 3,
            'volumeMulti': 1.5,
            'rsiThreshold': 35,
            'macdThreshold': 0,
            'useMa5AboveMa20': True,
            'usePriceAboveMa5': True,
            'useMacdRising': True,
            'useRsiBelow35': True,
            'useVolumeAboveMa': True,
            'usePriceBelowBoll': True,
            'useAdxConfirm': True,
            'useMomentumConfirm': True
        },
        'volume_breakout': {
            'breakoutPeriod': 20,
            'volumeMulti': 2.0,
            'rsiMax': 70,
            'minConditions': 3,
            'scoreThreshold': 70,
            'usePriceBreakout': True,
            'useVolumeUp': True,
            'useTrendConfirm': True,
            'useVolatilityConfirm': True,
            'useMomentumConfirm': True,
            'useBullishCandle': True,
            'useChipConfirm': True
        },
        'oversold_rebound': {
            'rsiOversold': 30,
            'bollingerOffset': 0.02,
            'nearLowRatio': 1.03,
            'minConditions': 3,
            'scoreThreshold': 65,
            'useRsiOversold': True,
            'useTouchLowerBoll': True,
            'useNearLow': True,
            'useVolumePattern': True,
            'useCandlePattern': True,
            'useMacdDivergence': True,
            'useTrendFilter': True
        },
        'trend_enhanced': {
            'macdThreshold': 0,
            'minConditions': 3,
            'scoreThreshold': 70,
            'useShortMaAlignment': True,
            'usePriceAboveMa': True,
            'useMacdPositive': True,
            'useAdxConfirm': True,
            'useVolumeConfirm': True,
            'useBollConfirm': True,
            'useMomentumConfirm': True,
            'useTrendPersistence': True
        },
        'macd_divergence': {
            'lookbackPeriod': 30,
            'minConditions': 2,
            'scoreThreshold': 60,
            'useBullishDivergence': True,
            'useHistogramDivergence': True,
            'useVolumeDivergence': True,
            'useRsiDivergence': True,
            'useTrendFilter': True,
            'useCandleConfirm': True,
            'useMaConfirm': True
        },
        'bollinger_extreme': {
            'bollDeviation': 2.0,
            'rsiOversold': 30,
            'minConditions': 2,
            'scoreThreshold': 60,
            'useLowerBandTouch': True,
            'useBandWidthConfirm': True,
            'useRsiConfirm': True,
            'useVolumeConfirm': True,
            'useMaSupport': True,
            'useCandleConfirm': True,
            'useVolatilityAdjust': True
        },
        'momentum_rotation': {
            'shortMomentumPeriod': 10,
            'shortMomentumThreshold': 3.0,
            'mediumMomentumPeriod': 20,
            'mediumMomentumThreshold': 5.0,
            'longMomentumPeriod': 60,
            'volumeMulti': 1.5,
            'minConditions': 3,
            'scoreThreshold': 65,
            'useShortMomentum': True,
            'useMediumMomentum': True,
            'useLongMomentum': True,
            'useRelativeStrength': True,
            'useVolumeConfirm': True,
            'useMomentumQuality': True,
            'useVolatilityAdjust': True,
            'useMacdConfirm': True
        },
        'turtle_enhanced': {
            'entryPeriod': 20,
            'exitPeriod': 10,
            'atrMultiplier': 2.0,
            'volumeMulti': 1.5,
            'minConditions': 3,
            'scoreThreshold': 65,
            'useBreakoutEntry': True,
            'useTrendFilter': True,
            'useVolatilityFilter': True,
            'useVolumeConfirm': True,
            'useAdxConfirm': True,
            'useFalseBreakoutFilter': True,
            'useRiskManagement': True,
            'useSentimentFilter': True
        }
    }
    
    # è¡Œä¸šç‰¹å®šå‚æ•°è°ƒæ•´
    INDUSTRY_ADJUSTMENTS = {
        'é“¶è¡Œ': {'rsiThreshold': 40, 'volumeMulti': 1.2, 'atr_multiplier': 0.8},
        'ä¿é™©': {'rsiThreshold': 38, 'volumeMulti': 1.3, 'atr_multiplier': 0.9},
        'æˆ¿åœ°äº§': {'rsiThreshold': 35, 'volumeMulti': 1.4, 'atr_multiplier': 1.1},
        'ç™½é…’': {'rsiThreshold': 35, 'volumeMulti': 1.5, 'atr_multiplier': 1.2},
        'åŒ»è¯': {'rsiThreshold': 33, 'volumeMulti': 1.6, 'atr_multiplier': 1.3},
        'ç§‘æŠ€': {'rsiThreshold': 30, 'volumeMulti': 1.8, 'atr_multiplier': 1.5},
        'åŠå¯¼ä½“': {'rsiThreshold': 30, 'volumeMulti': 2.0, 'atr_multiplier': 1.6},
        'æ–°èƒ½æº': {'rsiThreshold': 32, 'volumeMulti': 1.8, 'atr_multiplier': 1.5},
        'åŒ–å·¥': {'rsiThreshold': 35, 'volumeMulti': 1.4, 'atr_multiplier': 1.1},
        'æœºæ¢°': {'rsiThreshold': 35, 'volumeMulti': 1.4, 'atr_multiplier': 1.2},
        'ç”µå­': {'rsiThreshold': 32, 'volumeMulti': 1.7, 'atr_multiplier': 1.4},
        'é€šä¿¡': {'rsiThreshold': 32, 'volumeMulti': 1.7, 'atr_multiplier': 1.4},
        'ä¼ åª’': {'rsiThreshold': 30, 'volumeMulti': 1.8, 'atr_multiplier': 1.5},
        'æ±½è½¦': {'rsiThreshold': 33, 'volumeMulti': 1.6, 'atr_multiplier': 1.3},
        'å®¶ç”µ': {'rsiThreshold': 35, 'volumeMulti': 1.4, 'atr_multiplier': 1.1},
        'é£Ÿå“': {'rsiThreshold': 36, 'volumeMulti': 1.3, 'atr_multiplier': 1.0},
        'æœè£…': {'rsiThreshold': 35, 'volumeMulti': 1.4, 'atr_multiplier': 1.2},
        'å»ºæ': {'rsiThreshold': 35, 'volumeMulti': 1.4, 'atr_multiplier': 1.2},
        'æœ‰è‰²': {'rsiThreshold': 32, 'volumeMulti': 1.7, 'atr_multiplier': 1.4},
        'é’¢é“': {'rsiThreshold': 35, 'volumeMulti': 1.4, 'atr_multiplier': 1.1},
        'ç…¤ç‚­': {'rsiThreshold': 35, 'volumeMulti': 1.4, 'atr_multiplier': 1.1},
        'çŸ³æ²¹': {'rsiThreshold': 36, 'volumeMulti': 1.3, 'atr_multiplier': 1.0},
        'ç”µåŠ›': {'rsiThreshold': 38, 'volumeMulti': 1.2, 'atr_multiplier': 0.9},
        'äº¤é€šè¿è¾“': {'rsiThreshold': 37, 'volumeMulti': 1.3, 'atr_multiplier': 0.9},
        'å»ºç­‘': {'rsiThreshold': 36, 'volumeMulti': 1.3, 'atr_multiplier': 1.0},
        'å†œæ—ç‰§æ¸”': {'rsiThreshold': 33, 'volumeMulti': 1.6, 'atr_multiplier': 1.3},
        'å•†è´¸é›¶å”®': {'rsiThreshold': 35, 'volumeMulti': 1.4, 'atr_multiplier': 1.1},
        'ç¤¾ä¼šæœåŠ¡': {'rsiThreshold': 33, 'volumeMulti': 1.6, 'atr_multiplier': 1.3},
        'è®¡ç®—æœº': {'rsiThreshold': 30, 'volumeMulti': 1.9, 'atr_multiplier': 1.6},
        'å›½é˜²å†›å·¥': {'rsiThreshold': 30, 'volumeMulti': 1.9, 'atr_multiplier': 1.6},
    }
    
    @classmethod
    def get_optimized_params(cls, strategy_name, stock_features=None, industry=None):
        """
        è·å–ä¼˜åŒ–åçš„å‚æ•°
        
        Args:
            strategy_name: ç­–ç•¥åç§°
            stock_features: è‚¡ç¥¨ç‰¹å¾å­—å…¸
            industry: è¡Œä¸šåç§°
        
        Returns:
            ä¼˜åŒ–åçš„å‚æ•°å­—å…¸
        """
        # è·å–åŸºç¡€é€šç”¨å‚æ•°
        params = cls.UNIVERSAL_PARAMS.get(strategy_name, {}).copy()
        
        # åº”ç”¨è¡Œä¸šç‰¹å®šè°ƒæ•´
        if industry and industry in cls.INDUSTRY_ADJUSTMENTS:
            industry_adj = cls.INDUSTRY_ADJUSTMENTS[industry]
            for key, value in industry_adj.items():
                if key in params:
                    params[key] = value
        
        # åº”ç”¨è‚¡ç¥¨ç‰¹å¾è‡ªé€‚åº”è°ƒæ•´
        if stock_features:
            params = cls._apply_feature_adjustments(params, stock_features)
        
        return params
    
    @classmethod
    def _apply_feature_adjustments(cls, params, stock_features):
        """æ ¹æ®è‚¡ç¥¨ç‰¹å¾è°ƒæ•´å‚æ•°"""
        # æ³¢åŠ¨ç‡è°ƒæ•´
        volatility = stock_features.get('volatility', 'medium')
        volatility_multipliers = {
            'very_high': {'stopLoss': 1.5, 'takeProfit': 1.3, 'rsiThreshold': 1.15, 'volumeMulti': 0.8},
            'high': {'stopLoss': 1.3, 'takeProfit': 1.2, 'rsiThreshold': 1.08, 'volumeMulti': 0.9},
            'medium': {'stopLoss': 1.0, 'takeProfit': 1.0, 'rsiThreshold': 1.0, 'volumeMulti': 1.0},
            'low': {'stopLoss': 0.8, 'takeProfit': 0.9, 'rsiThreshold': 0.92, 'volumeMulti': 1.1},
            'very_low': {'stopLoss': 0.7, 'takeProfit': 0.8, 'rsiThreshold': 0.85, 'volumeMulti': 1.2}
        }
        
        vm = volatility_multipliers.get(volatility, volatility_multipliers['medium'])
        
        # åº”ç”¨æ³¢åŠ¨ç‡è°ƒæ•´
        for param_key, multiplier in vm.items():
            if param_key in params and isinstance(params[param_key], (int, float)):
                params[param_key] = params[param_key] * multiplier
        
        # æµåŠ¨æ€§è°ƒæ•´
        liquidity = stock_features.get('liquidity', 'medium')
        liquidity_adjustments = {
            'very_high': {'scoreThreshold': -5, 'minConditions': -1},
            'high': {'scoreThreshold': -3, 'minConditions': 0},
            'medium': {'scoreThreshold': 0, 'minConditions': 0},
            'low': {'scoreThreshold': 5, 'minConditions': 1},
            'very_low': {'scoreThreshold': 10, 'minConditions': 1}
        }
        
        la = liquidity_adjustments.get(liquidity, liquidity_adjustments['medium'])
        
        for param_key, adjustment in la.items():
            if param_key in params:
                params[param_key] = params[param_key] + adjustment
        
        # è¶‹åŠ¿ç±»å‹è°ƒæ•´
        trend_type = stock_features.get('trend_type', 'neutral')
        trend_adjustments = {
            'strong_uptrend': {'macdThreshold': 0.3, 'scoreThreshold': 5},
            'weak_uptrend': {'macdThreshold': 0.1, 'scoreThreshold': 0},
            'sideways': {'macdThreshold': 0, 'scoreThreshold': 0},
            'weak_downtrend': {'macdThreshold': -0.1, 'scoreThreshold': -5},
            'strong_downtrend': {'macdThreshold': -0.3, 'scoreThreshold': -10},
            'neutral': {'macdThreshold': 0, 'scoreThreshold': 0}
        }
        
        ta = trend_adjustments.get(trend_type, trend_adjustments['neutral'])
        
        for param_key, adjustment in ta.items():
            if param_key in params:
                params[param_key] = params[param_key] + adjustment
        
        return params
    
    @classmethod
    def validate_params(cls, strategy_name, params):
        """éªŒè¯å‚æ•°æœ‰æ•ˆæ€§"""
        validated = params.copy()
        
        # ç¡®ä¿æ•°å€¼å‚æ•°åœ¨åˆç†èŒƒå›´å†…
        if 'rsiThreshold' in validated:
            validated['rsiThreshold'] = max(10, min(50, validated['rsiThreshold']))
        
        if 'rsiOversold' in validated:
            validated['rsiOversold'] = max(5, min(40, validated['rsiOversold']))
        
        if 'rsiOverbought' in validated:
            validated['rsiOverbought'] = max(60, min(95, validated['rsiOverbought']))
        
        if 'volumeMulti' in validated:
            validated['volumeMulti'] = max(1.0, min(5.0, validated['volumeMulti']))
        
        if 'stopLoss' in validated:
            validated['stopLoss'] = max(0.03, min(0.20, validated['stopLoss']))
        
        if 'takeProfit' in validated:
            validated['takeProfit'] = max(0.05, min(0.50, validated['takeProfit']))
        
        if 'scoreThreshold' in validated:
            validated['scoreThreshold'] = max(40, min(85, validated['scoreThreshold']))
        
        if 'minConditions' in validated:
            validated['minConditions'] = max(1, min(6, int(validated['minConditions'])))
        
        return validated


class StockFeatureAnalyzer:
    """è‚¡ç¥¨ç‰¹å¾åˆ†æå™¨ - ç”¨äºè‡ªé€‚åº”å‚æ•°è°ƒæ•´"""
    
    @staticmethod
    def analyze_stock_features(df):
        """åˆ†æè‚¡ç¥¨ç‰¹å¾ï¼Œè¿”å›ç‰¹å¾å­—å…¸"""
        if df is None or len(df) < 60:
            return {
                'volatility': 'medium',
                'liquidity': 'medium',
                'trend_type': 'neutral',
                'industry_style': 'general',
                'market_cap_category': 'mid',
                'volatility_atr_pct': 2.0,
                'avg_volume': 1000000,
                'price_level': 50
            }
        
        latest = df.iloc[-1]
        
        # 1. æ³¢åŠ¨ç‡ç‰¹å¾ (åŸºäºATRç™¾åˆ†æ¯”)
        atr_pct = latest.get('atr_pct', 2.0)
        if atr_pct > 4:
            volatility = 'very_high'
        elif atr_pct > 2.5:
            volatility = 'high'
        elif atr_pct > 1.5:
            volatility = 'medium'
        elif atr_pct > 0.8:
            volatility = 'low'
        else:
            volatility = 'very_low'
        
        # 2. æµåŠ¨æ€§ç‰¹å¾ (åŸºäºæˆäº¤é‡)
        avg_volume = df['volume'].mean() if 'volume' in df.columns else 1000000
        if avg_volume > 50000000:
            liquidity = 'very_high'
        elif avg_volume > 10000000:
            liquidity = 'high'
        elif avg_volume > 2000000:
            liquidity = 'medium'
        elif avg_volume > 500000:
            liquidity = 'low'
        else:
            liquidity = 'very_low'
        
        # 3. è¶‹åŠ¿ç±»å‹
        if len(df) >= 60:
            price_change_60d = (df.iloc[-1]['close'] - df.iloc[-60]['close']) / df.iloc[-60]['close'] * 100
            if price_change_60d > 30:
                trend_type = 'strong_uptrend'
            elif price_change_60d > 10:
                trend_type = 'weak_uptrend'
            elif price_change_60d < -30:
                trend_type = 'strong_downtrend'
            elif price_change_60d < -10:
                trend_type = 'weak_downtrend'
            else:
                trend_type = 'sideways'
        else:
            trend_type = 'neutral'
        
        # 4. ä»·æ ¼æ°´å¹³
        price_level = latest.get('close', 50)
        if price_level > 200:
            price_category = 'very_high'
        elif price_level > 100:
            price_category = 'high'
        elif price_level > 50:
            price_category = 'medium'
        elif price_level > 20:
            price_category = 'low'
        else:
            price_category = 'very_low'
        
        # 5. æ³¢åŠ¨ç‡ç¨³å®šæ€§
        if len(df) >= 20:
            atr_std = df['atr_pct'].std() if 'atr_pct' in df.columns else 0
            if atr_std > 2:
                volatility_stability = 'unstable'
            elif atr_std > 1:
                volatility_stability = 'moderate'
            else:
                volatility_stability = 'stable'
        else:
            volatility_stability = 'moderate'
        
        return {
            'volatility': volatility,
            'volatility_atr_pct': atr_pct,
            'liquidity': liquidity,
            'avg_volume': avg_volume,
            'trend_type': trend_type,
            'price_level': price_level,
            'price_category': price_category,
            'volatility_stability': volatility_stability,
            'boll_width': latest.get('bollWidth', 0.1),
            'adx': latest.get('adx', 25)
        }
    
    @staticmethod
    def get_adaptive_params(base_config, stock_features):
        """æ ¹æ®è‚¡ç¥¨ç‰¹å¾è·å–è‡ªé€‚åº”å‚æ•°"""
        config = base_config.copy()
        
        # æ³¢åŠ¨ç‡è°ƒæ•´å› å­
        volatility_factors = {
            'very_high': {'stop_loss_mult': 1.5, 'take_profit_mult': 1.3, 'rsi_threshold_adj': 5, 'volume_mult': 0.8},
            'high': {'stop_loss_mult': 1.3, 'take_profit_mult': 1.2, 'rsi_threshold_adj': 3, 'volume_mult': 0.9},
            'medium': {'stop_loss_mult': 1.0, 'take_profit_mult': 1.0, 'rsi_threshold_adj': 0, 'volume_mult': 1.0},
            'low': {'stop_loss_mult': 0.8, 'take_profit_mult': 0.9, 'rsi_threshold_adj': -3, 'volume_mult': 1.1},
            'very_low': {'stop_loss_mult': 0.7, 'take_profit_mult': 0.8, 'rsi_threshold_adj': -5, 'volume_mult': 1.2}
        }
        
        vf = volatility_factors.get(stock_features['volatility'], volatility_factors['medium'])
        
        # è°ƒæ•´æ­¢æŸæ­¢ç›ˆ
        if 'stopLoss' in config:
            config['stopLoss'] = config['stopLoss'] * vf['stop_loss_mult']
        if 'takeProfit' in config:
            config['takeProfit'] = config['takeProfit'] * vf['take_profit_mult']
        
        # è°ƒæ•´RSIé˜ˆå€¼
        if 'rsiThreshold' in config:
            config['rsiThreshold'] = config['rsiThreshold'] + vf['rsi_threshold_adj']
        if 'rsiOversold' in config:
            config['rsiOversold'] = max(10, config['rsiOversold'] + vf['rsi_threshold_adj'])
        if 'rsiOverbought' in config:
            config['rsiOverbought'] = min(90, config['rsiOverbought'] - vf['rsi_threshold_adj'])
        
        # è°ƒæ•´æˆäº¤é‡å€æ•°
        if 'volumeMulti' in config:
            config['volumeMulti'] = config['volumeMulti'] * vf['volume_mult']
        
        # è¶‹åŠ¿ç±»å‹è°ƒæ•´
        trend_factors = {
            'strong_uptrend': {'macd_threshold_adj': 0.5, 'ma_bias': 0.02},
            'weak_uptrend': {'macd_threshold_adj': 0.2, 'ma_bias': 0.01},
            'sideways': {'macd_threshold_adj': 0, 'ma_bias': 0},
            'weak_downtrend': {'macd_threshold_adj': -0.2, 'ma_bias': -0.01},
            'strong_downtrend': {'macd_threshold_adj': -0.5, 'ma_bias': -0.02},
            'neutral': {'macd_threshold_adj': 0, 'ma_bias': 0}
        }
        
        tf = trend_factors.get(stock_features['trend_type'], trend_factors['neutral'])
        
        if 'macdThreshold' in config:
            config['macdThreshold'] = config['macdThreshold'] + tf['macd_threshold_adj']
        
        # æµåŠ¨æ€§è°ƒæ•´
        liquidity_factors = {
            'very_high': {'position_size_mult': 1.2, 'slippage': 0.001},
            'high': {'position_size_mult': 1.1, 'slippage': 0.002},
            'medium': {'position_size_mult': 1.0, 'slippage': 0.003},
            'low': {'position_size_mult': 0.8, 'slippage': 0.005},
            'very_low': {'position_size_mult': 0.6, 'slippage': 0.008}
        }
        
        lf = liquidity_factors.get(stock_features['liquidity'], liquidity_factors['medium'])
        
        if 'positionSizeMult' in config:
            config['positionSizeMult'] = config['positionSizeMult'] * lf['position_size_mult']
        
        return config


class StrategyEngine:
    """ç­–ç•¥å¼•æ“"""
    
    STRATEGIES = {
        'deep_fusion': {
            'name': 'æ·±åº¦èåˆç­–ç•¥',
            'icon': 'ğŸ¤–',
            'description': 'èåˆå¤šæŠ€æœ¯æŒ‡æ ‡ï¼Œé€šè¿‡åŠ æƒè¯„åˆ†+ç¡®è®¤ä¿¡å·æœºåˆ¶å†³ç­–ï¼Œæ”¯æŒè‡ªé€‚åº”å‚æ•°è°ƒæ•´',
            'features': ['MAå¯¹é½ç¡®è®¤', 'MACDåŠ¨é‡', 'RSIè¶…å–', 'æˆäº¤é‡ç¡®è®¤', 'å¸ƒæ—å¸¦ä½ç½®', 'ADXè¶‹åŠ¿å¼ºåº¦', 'ä»·æ ¼åŠ¨é‡']
        },
        'volume_breakout': {
            'name': 'é‡ä»·çªç ´ç­–ç•¥',
            'icon': 'âš¡',
            'description': 'å¤šç»´åº¦çªç ´ç¡®è®¤ï¼šä»·æ ¼çªç ´+æˆäº¤é‡æ”¾å¤§+è¶‹åŠ¿å¯¹é½+æ³¢åŠ¨ç‡è¿‡æ»¤',
            'features': ['ä»·æ ¼çªç ´', 'æˆäº¤é‡æ¿€å¢', 'è¶‹åŠ¿ç¡®è®¤', 'æ³¢åŠ¨ç‡è¿‡æ»¤', 'åŠ¨èƒ½ç¡®è®¤', 'Kçº¿å½¢æ€', 'ç­¹ç åˆ†å¸ƒ']
        },
        'oversold_rebound': {
            'name': 'è¶…è·Œåå¼¹ç­–ç•¥',
            'icon': 'ğŸ’',
            'description': 'å¤šç»´åº¦è¶…å–ç¡®è®¤+åå¼¹ä¿¡å·æ£€æµ‹ï¼šRSIèƒŒç¦»+MACDèƒŒç¦»+Kçº¿å½¢æ€',
            'features': ['RSIè¶…å–', 'å¸ƒæ—ä¸‹è½¨', 'ä»·æ ¼ä½ç‚¹', 'æˆäº¤é‡æ¨¡å¼', 'Kçº¿å½¢æ€', 'MACDèƒŒç¦»', 'è¶‹åŠ¿è¿‡æ»¤']
        },
        'trend_enhanced': {
            'name': 'è¶‹åŠ¿å¢å¼ºç­–ç•¥',
            'icon': 'ğŸ“ˆ',
            'description': 'å¤šæ—¶é—´æ¡†æ¶è¶‹åŠ¿ç¡®è®¤ï¼šå‡çº¿æ’åˆ—+ADXå¼ºåº¦+æˆäº¤é‡è¶‹åŠ¿+åŠ¨é‡ç¡®è®¤',
            'features': ['å‡çº¿æ’åˆ—', 'ä»·æ ¼ä½ç½®', 'MACDåŠ¨èƒ½', 'ADXå¼ºåº¦', 'æˆäº¤é‡è¶‹åŠ¿', 'å¸ƒæ—å¸¦è¶‹åŠ¿', 'è¶‹åŠ¿æŒç»­æ€§']
        },
        'macd_divergence': {
            'name': 'MACDèƒŒç¦»ç­–ç•¥',
            'icon': 'ğŸ¯',
            'description': 'å¤šå‘¨æœŸèƒŒç¦»æ£€æµ‹ï¼šä»·æ ¼-MACDèƒŒç¦»+æˆäº¤é‡èƒŒç¦»+RSIèƒŒç¦»+Kçº¿å½¢æ€ç¡®è®¤',
            'features': ['åº•èƒŒç¦»æ£€æµ‹', 'æŸ±çŠ¶å›¾èƒŒç¦»', 'æˆäº¤é‡èƒŒç¦»', 'RSIèƒŒç¦»', 'è¶‹åŠ¿è¿‡æ»¤', 'Kçº¿å½¢æ€', 'å‡çº¿ç¡®è®¤']
        },
        'bollinger_extreme': {
            'name': 'å¸ƒæ—æé™ç­–ç•¥',
            'icon': 'ğŸ“Š',
            'description': 'å¸ƒæ—å¸¦æå€¼äº¤æ˜“+åè½¬ç¡®è®¤ï¼šä¸‹è½¨è§¦åŠ+RSIè¶…å–+æˆäº¤é‡åœ°é‡+Kçº¿å½¢æ€',
            'features': ['ä¸‹è½¨è§¦åŠ', 'å¸¦å®½ç¡®è®¤', 'RSIè¶…å–', 'æˆäº¤é‡ç¡®è®¤', 'å‡çº¿æ”¯æ’‘', 'Kçº¿å½¢æ€', 'æ³¢åŠ¨ç‡è°ƒæ•´']
        },
        'momentum_rotation': {
            'name': 'åŠ¨é‡è½®åŠ¨ç­–ç•¥',
            'icon': 'âš¡',
            'description': 'å¤šå‘¨æœŸåŠ¨é‡ç¡®è®¤+ç›¸å¯¹å¼ºåº¦åˆ†æï¼šçŸ­ä¸­é•¿æœŸåŠ¨é‡+åŠ¨é‡è´¨é‡+æ³¢åŠ¨ç‡åŒ¹é…',
            'features': ['çŸ­æœŸåŠ¨é‡', 'ä¸­æœŸåŠ¨é‡', 'é•¿æœŸåŠ¨é‡', 'ç›¸å¯¹å¼ºåº¦', 'æˆäº¤é‡ç¡®è®¤', 'åŠ¨é‡è´¨é‡', 'MACDç¡®è®¤']
        },
        'turtle_enhanced': {
            'name': 'æµ·é¾Ÿå¢å¼ºç­–ç•¥',
            'icon': 'ğŸ¢',
            'description': 'å¤šæ—¶é—´æ¡†æ¶çªç ´+é£é™©ç®¡ç†å¢å¼ºï¼šçªç ´ç¡®è®¤+è¶‹åŠ¿è¿‡æ»¤+å‡çªç ´è¿‡æ»¤+é£é™©è¯„åˆ†',
            'features': ['çªç ´å…¥åœº', 'è¶‹åŠ¿è¿‡æ»¤', 'æ³¢åŠ¨ç‡è¿‡æ»¤', 'æˆäº¤é‡ç¡®è®¤', 'ADXå¼ºåº¦', 'å‡çªç ´è¿‡æ»¤', 'é£é™©ç®¡ç†']
        }
    }
    
    @staticmethod
    def execute_strategy(data, strategy_name, config, stock_features=None):
        """æ‰§è¡Œç­–ç•¥ - ä¼˜åŒ–ç‰ˆï¼Œæ”¯æŒè‡ªé€‚åº”å‚æ•°è°ƒæ•´"""
        df = pd.DataFrame(data)
        signals = []
        position = 0
        entry_price = 0
        entry_index = 0
        highest_since_entry = 0
        last_sell_index = -999  # è®°å½•ä¸Šä¸€æ¬¡å–å‡ºçš„ç´¢å¼•
        
        # åˆ†æè‚¡ç¥¨ç‰¹å¾å¹¶åº”ç”¨è‡ªé€‚åº”å‚æ•°
        if stock_features is None:
            stock_features = StockFeatureAnalyzer.analyze_stock_features(df)
        
        # åº”ç”¨è‡ªé€‚åº”å‚æ•°è°ƒæ•´
        config = StockFeatureAnalyzer.get_adaptive_params(config, stock_features)
        
        buy_cooldown = int(config.get('buyCooldown', 1))  # ä¹°å…¥å†·å´å¤©æ•°ï¼Œé»˜è®¤1å¤©

        # è·å–å¸‚åœºçŠ¶æ€ï¼ˆç”¨äºåŠ¨æ€è°ƒæ•´ç­–ç•¥å‚æ•°ï¼‰
        market_state = 'neutral'
        if len(df) > 0 and 'market_state' in df.columns:
            market_state = df.iloc[-1].get('market_state', 'neutral')
        
        # å¸‚åœºçŠ¶æ€æƒé‡è°ƒæ•´
        market_adjustments = {
            'bull_market': {'aggressive': 1.1, 'conservative': 0.9},
            'bear_market': {'aggressive': 0.8, 'conservative': 1.2},
            'sideways_market': {'aggressive': 0.9, 'conservative': 1.1},
            'volatile_market': {'aggressive': 1.0, 'conservative': 1.0},
            'choppy_market': {'aggressive': 0.7, 'conservative': 1.3}
        }
        aggressive_factor = market_adjustments.get(market_state, {}).get('aggressive', 1.0)
        conservative_factor = market_adjustments.get(market_state, {}).get('conservative', 1.0)

        for i in range(60, len(df)):
            d = df.iloc[i]
            prev = df.iloc[i-1]
            
            if pd.isna(d.get('ma20')) or pd.isna(d.get('rsi')):
                continue
            
            buy_signal = False
            sell_signal = False
            signal_strength = 50
            sell_reason = ''
            
            # å†·å´æœŸæ£€æŸ¥
            in_cooldown = (i - last_sell_index) <= buy_cooldown

            # ç­–ç•¥é€»è¾‘ - ä¼˜åŒ–ç‰ˆ
            if not in_cooldown and position == 0:
                if strategy_name == 'deep_fusion':
                    # æ·±åº¦èåˆç­–ç•¥ - å‡çº§ç‰ˆï¼šå¤šæ¡ä»¶åŠ æƒè¯„åˆ† + åŠ¨æ€ç¡®è®¤æœºåˆ¶
                    score = 0
                    max_score = 0
                    confirmations = 0  # ç¡®è®¤ä¿¡å·è®¡æ•°
                    
                    # 1. MAå¯¹é½æ¡ä»¶ï¼ˆå¯é…ç½®å¼€å…³ï¼‰- æƒé‡å¢åŠ 
                    if config.get('useMa5AboveMa20', True):
                        max_score += 25
                        if d['ma5'] and d['ma20'] and d['ma5'] > d['ma20']:
                            score += 25
                            confirmations += 1
                            # å¤šå¤´æ’åˆ—åŠ åˆ†
                            if d.get('ma10') and d.get('ma20') and d['ma10'] > d['ma20']:
                                score += 5
                    
                    # 2. ä»·æ ¼ä½ç½®æ¡ä»¶ï¼ˆå¯é…ç½®å¼€å…³ï¼‰
                    if config.get('usePriceAboveMa5', True):
                        max_score += 15
                        if d['close'] > d.get('ma5', d['close']):
                            score += 15
                            confirmations += 1
                    
                    # 3. MACDåŠ¨é‡æ¡ä»¶ï¼ˆå¯é…ç½®å¼€å…³ï¼‰- å¢å¼ºåˆ¤æ–­
                    if config.get('useMacdRising', True):
                        max_score += 25
                        macd_threshold = config.get('macdThreshold', 0)
                        if d['macd'] and d['macd'] > macd_threshold:
                            # MACDæŸ±çŠ¶å›¾ä¸Šå‡
                            if d['macd'] > prev.get('macd', 0):
                                score += 20
                                confirmations += 1
                            # DIFä¸Šç©¿DEAé‡‘å‰
                            if d.get('macdHist') and prev.get('macdHist'):
                                if d['macdHist'] > 0 and prev['macdHist'] <= 0:
                                    score += 10  # é‡‘å‰åŠ åˆ†
                    
                    # 4. RSIè¶…å–æ¡ä»¶ï¼ˆå¯é…ç½®å¼€å…³ï¼‰- åŠ¨æ€é˜ˆå€¼
                    if config.get('useRsiBelow35', True):
                        max_score += 15
                        rsi_threshold = config.get('rsiThreshold', 35)
                        if d['rsi'] and d['rsi'] < rsi_threshold:
                            score += 15
                            confirmations += 1
                            # ä¸¥é‡è¶…å–é¢å¤–åŠ åˆ†
                            if d['rsi'] < 25:
                                score += 10
                    
                    # 5. æˆäº¤é‡ç¡®è®¤æ¡ä»¶ï¼ˆå¯é…ç½®å¼€å…³ï¼‰- å¢å¼ºåˆ¤æ–­
                    if config.get('useVolumeAboveMa', True):
                        max_score += 20
                        vol_multi = config.get('volumeMulti', 1.5)
                        if d['volume'] and d.get('volMa5') and d['volume'] > d['volMa5'] * vol_multi:
                            score += 15
                            confirmations += 1
                            # æˆäº¤é‡æŒç»­æ”¾å¤§
                            if d.get('volMa5') and d.get('volMa10') and d['volMa5'] > d['volMa10']:
                                score += 5
                    
                    # 6. å¸ƒæ—å¸¦ä½ç½®æ¡ä»¶ï¼ˆå¯é…ç½®å¼€å…³ï¼‰- ä¼˜åŒ–åˆ¤æ–­
                    if config.get('usePriceBelowBoll', True):
                        max_score += 15
                        if d['close'] and d.get('bollDown') and d['close'] < d['bollDown']:
                            score += 15
                            confirmations += 1
                            # è§¦åŠä¸‹è½¨ä¸”åå¼¹
                            if d['close'] > d['open']:
                                score += 5
                    
                    # 7. æ–°å¢ï¼šADXè¶‹åŠ¿å¼ºåº¦ç¡®è®¤
                    if config.get('useAdxConfirm', True):
                        max_score += 10
                        if d.get('adx') and d['adx'] > 20:
                            score += 10
                            if d.get('plus_di') and d.get('minus_di') and d['plus_di'] > d['minus_di']:
                                score += 5
                    
                    # 8. æ–°å¢ï¼šä»·æ ¼åŠ¨é‡ç¡®è®¤
                    if config.get('useMomentumConfirm', True):
                        max_score += 10
                        if i >= 5:
                            price_change_5d = (d['close'] - df.iloc[i-5]['close']) / df.iloc[i-5]['close'] * 100
                            if -10 < price_change_5d < 5:  # è¿‘æœŸæ²¡æœ‰å¤§æ¶¨å¤§è·Œ
                                score += 10
                    
                    # åŠ¨æ€é˜ˆå€¼è°ƒæ•´ - åŸºäºç¡®è®¤ä¿¡å·æ•°é‡
                    base_threshold = config.get('mlScoreThreshold', 60)
                    # ç¡®è®¤ä¿¡å·è¶Šå¤šï¼Œé˜ˆå€¼å¯ä»¥é€‚å½“é™ä½
                    confirmation_bonus = confirmations * 2
                    adjusted_threshold = (base_threshold - confirmation_bonus) * conservative_factor
                    adjusted_threshold = max(45, min(75, adjusted_threshold))  # é™åˆ¶åœ¨45-75ä¹‹é—´
                    
                    signal_strength = (score / max_score * 100) if max_score > 0 else 50
                    
                    # ä¹°å…¥æ¡ä»¶ï¼šè¾¾åˆ°é˜ˆå€¼ä¸”è‡³å°‘æœ‰3ä¸ªç¡®è®¤ä¿¡å·
                    min_confirmations = config.get('minConfirmations', 3)
                    if signal_strength >= adjusted_threshold and confirmations >= min_confirmations:
                        buy_signal = True
                        # æ ¹æ®ç¡®è®¤ä¿¡å·æ•°é‡è°ƒæ•´ä¿¡å·å¼ºåº¦
                        signal_strength = min(95, signal_strength + confirmations * 3)
                    
                elif strategy_name == 'volume_breakout':
                    # é‡ä»·çªç ´ç­–ç•¥ - å‡çº§ç‰ˆï¼šå¤šç»´åº¦çªç ´ç¡®è®¤
                    conditions_met = 0
                    total_conditions = 0
                    breakout_score = 0
                    
                    # 1. ä»·æ ¼çªç ´æ¡ä»¶ï¼ˆæ ¸å¿ƒï¼‰- å¢å¼ºåˆ¤æ–­
                    if config.get('usePriceBreakout', True):
                        total_conditions += 1
                        breakout_period = config.get('breakoutPeriod', 20)
                        high_col = f'high{breakout_period}'
                        
                        if d.get(high_col) and d['close'] > d[high_col] * 0.995:  # å…è®¸0.5%çš„è¯¯å·®
                            conditions_met += 1
                            breakout_score += 30
                            # åˆ›è¿‘æœŸæ–°é«˜åŠ åˆ†
                            if d['close'] > d.get('high60', d['close']):
                                breakout_score += 10
                    
                    # 2. æˆäº¤é‡æ”¾å¤§æ¡ä»¶ï¼ˆæ ¸å¿ƒï¼‰- åŠ¨æ€é˜ˆå€¼
                    if config.get('useVolumeUp', True):
                        total_conditions += 1
                        vol_multi = config.get('volumeMulti', 2.0)
                        vol_ratio = d['volume'] / d['volMa5'] if d.get('volMa5') and d['volMa5'] > 0 else 0
                        
                        if vol_ratio > vol_multi:
                            conditions_met += 1
                            breakout_score += 25
                            # æˆäº¤é‡æŒç»­æ”¾å¤§
                            if d.get('volMa5') and d.get('volMa10') and d['volMa5'] > d['volMa10'] * 1.2:
                                breakout_score += 10
                            # å¼‚å¸¸æ”¾é‡è¿‡æ»¤ï¼ˆé¿å…å‡çªç ´ï¼‰
                            if vol_ratio < 5:  # æˆäº¤é‡ä¸è¶…è¿‡5å€ï¼Œé¿å…æç«¯æƒ…å†µ
                                breakout_score += 5
                    
                    # 3. è¶‹åŠ¿ç¡®è®¤æ¡ä»¶ - ç¡®ä¿çªç ´æ–¹å‘ä¸è¶‹åŠ¿ä¸€è‡´
                    if config.get('useTrendConfirm', True):
                        total_conditions += 1
                        if d.get('ma5') and d.get('ma20') and d['ma5'] > d['ma20']:
                            conditions_met += 1
                            breakout_score += 15
                            # å¤šå¤´æ’åˆ—åŠ åˆ†
                            if d.get('ma10') and d['ma10'] > d['ma20']:
                                breakout_score += 5
                    
                    # 4. æ³¢åŠ¨ç‡ç¡®è®¤ - é¿å…åœ¨éœ‡è¡å¸‚ä¸­äº¤æ˜“
                    if config.get('useVolatilityConfirm', True):
                        total_conditions += 1
                        if d.get('bollWidth') and d['bollWidth'] > 0.05:  # å¸ƒæ—å¸¦å®½åº¦è¶³å¤Ÿ
                            conditions_met += 1
                            breakout_score += 10
                    
                    # 5. åŠ¨èƒ½ç¡®è®¤ - RSIä¸è¿‡ä¹°
                    if config.get('useMomentumConfirm', True):
                        total_conditions += 1
                        rsi_max = config.get('rsiMax', 70)
                        if d.get('rsi') and d['rsi'] < rsi_max:
                            conditions_met += 1
                            breakout_score += 10
                    
                    # 6. é˜³çº¿ç¡®è®¤ï¼ˆåŠ åˆ†é¡¹ï¼‰
                    if config.get('useBullishCandle', True):
                        body_pct = abs(d['close'] - d['open']) / d['open'] * 100 if d['open'] > 0 else 0
                        if d['close'] > d['open']:  # é˜³çº¿
                            breakout_score += 10
                            if body_pct > 2:  # å¤§é˜³çº¿é¢å¤–åŠ åˆ†
                                breakout_score += 5
                        # ä¸Šå½±çº¿ä¸èƒ½å¤ªé•¿
                        upper_shadow = (d['high'] - max(d['close'], d['open'])) / d['open'] * 100 if d['open'] > 0 else 0
                        if upper_shadow < 2:
                            breakout_score += 5
                    
                    # 7. æ–°å¢ï¼šç­¹ç åˆ†å¸ƒç¡®è®¤ - çªç ´é˜»åŠ›ä½
                    if config.get('useChipConfirm', True):
                        if d.get('price_position_20') and d['price_position_20'] > 70:
                            breakout_score += 10
                    
                    # åŠ¨æ€ä¹°å…¥æ¡ä»¶
                    min_conditions = config.get('minConditions', 3)
                    score_threshold = config.get('scoreThreshold', 70)
                    
                    if conditions_met >= min_conditions and breakout_score >= score_threshold:
                        buy_signal = True
                        signal_strength = min(95, breakout_score)
                    
                elif strategy_name == 'oversold_rebound':
                    # è¶…è·Œåå¼¹ç­–ç•¥ - å‡çº§ç‰ˆï¼šå¤šç»´åº¦è¶…å–ç¡®è®¤ + åå¼¹ä¿¡å·æ£€æµ‹
                    conditions_met = 0
                    total_conditions = 0
                    rebound_score = 0
                    
                    # 1. RSIè¶…å–æ¡ä»¶ï¼ˆæ ¸å¿ƒï¼‰- åŠ¨æ€é˜ˆå€¼
                    if config.get('useRsiOversold', True):
                        total_conditions += 1
                        rsi_threshold = config.get('rsiOversold', 30)
                        if d.get('rsi') and d['rsi'] < rsi_threshold:
                            conditions_met += 1
                            rebound_score += 25
                            # ä¸¥é‡è¶…å–åŠ åˆ†
                            if d['rsi'] < 20:
                                rebound_score += 10
                            # RSIå¼€å§‹å›å‡ï¼ˆåº•èƒŒç¦»è¿¹è±¡ï¼‰
                            if prev.get('rsi') and d['rsi'] > prev['rsi']:
                                rebound_score += 10
                    
                    # 2. è§¦åŠå¸ƒæ—ä¸‹è½¨ï¼ˆå¯é…ç½®å¼€å…³ï¼‰- å¢å¼ºåˆ¤æ–­
                    if config.get('useTouchLowerBoll', True):
                        total_conditions += 1
                        boll_offset = config.get('bollingerOffset', 0.02)
                        if d.get('bollDown') and d['close'] < (d['bollDown'] * (1 + boll_offset)):
                            conditions_met += 1
                            rebound_score += 20
                            # è§¦åŠä¸‹è½¨ä¸”æ”¶é˜³çº¿
                            if d['close'] > d['open']:
                                rebound_score += 10
                    
                    # 3. ä»·æ ¼ä½ç½®æ¡ä»¶ - æ¥è¿‘è¿‘æœŸä½ç‚¹
                    if config.get('useNearLow', True):
                        total_conditions += 1
                        near_low_ratio = config.get('nearLowRatio', 1.03)
                        if d.get('low20') and d['close'] < d['low20'] * near_low_ratio:
                            conditions_met += 1
                            rebound_score += 15
                    
                    # 4. æˆäº¤é‡æ¡ä»¶ - ç¼©é‡åæ”¾é‡
                    if config.get('useVolumePattern', True):
                        total_conditions += 1
                        # ç¼©é‡ï¼ˆåœ°é‡ï¼‰
                        vol_ratio = d['volume'] / d['volMa5'] if d.get('volMa5') and d['volMa5'] > 0 else 1
                        if vol_ratio < 0.8:  # ç¼©é‡
                            rebound_score += 10
                            conditions_met += 1
                        # æˆ–è€…æ”¾é‡åå¼¹
                        elif d['close'] > d['open'] and vol_ratio > 1.2:
                            rebound_score += 15
                            conditions_met += 1
                    
                    # 5. Kçº¿å½¢æ€ç¡®è®¤ - çœ‹æ¶¨åè½¬å½¢æ€
                    if config.get('useCandlePattern', True):
                        body = d['close'] - d['open']
                        lower_shadow = d['open'] - d['low'] if body > 0 else d['close'] - d['low']
                        upper_shadow = d['high'] - d['close'] if body > 0 else d['high'] - d['open']
                        body_size = abs(body)
                        
                        # é”¤å­çº¿å½¢æ€
                        if lower_shadow > body_size * 2 and upper_shadow < body_size * 0.5:
                            rebound_score += 15
                        # å¯æ˜æ˜Ÿå½¢æ€ï¼ˆç®€åŒ–ç‰ˆï¼‰
                        if i >= 2:
                            prev2 = df.iloc[i-2]
                            if prev2['close'] < prev2['open']:  # å‰ä¸€å¤©é˜´çº¿
                                if body > 0 and d['close'] > (prev2['open'] + prev2['close']) / 2:
                                    rebound_score += 10
                    
                    # 6. MACDåº•èƒŒç¦»æ£€æµ‹
                    if config.get('useMacdDivergence', True):
                        if d.get('macd') and prev.get('macd'):
                            # ä»·æ ¼åˆ›æ–°ä½ä½†MACDæœªåˆ›æ–°ä½
                            if i >= 5:
                                price_low_now = d['close'] < df.iloc[i-5:i]['close'].min()
                                price_low_prev = df.iloc[i-5]['close'] < df.iloc[i-10:i-5]['close'].min() if i >= 10 else False
                                macd_now = d['macd']
                                macd_prev = df.iloc[i-5]['macd'] if i >= 5 else 0
                                
                                if price_low_now and not price_low_prev and macd_now > macd_prev:
                                    rebound_score += 20
                                    conditions_met += 1
                    
                    # 7. è¶‹åŠ¿è¿‡æ»¤ - é¿å…åœ¨å¼ºä¸‹è·Œè¶‹åŠ¿ä¸­ä¹°å…¥
                    if config.get('useTrendFilter', True):
                        if d.get('adx') and d['adx'] < 30:  # è¶‹åŠ¿ä¸å¼º
                            rebound_score += 10
                        # æˆ–è€…è¶‹åŠ¿å¼€å§‹è½¬å¼±
                        if d.get('minus_di') and d.get('plus_di') and d['minus_di'] < prev.get('minus_di', 100):
                            rebound_score += 5
                    
                    # åŠ¨æ€ä¹°å…¥æ¡ä»¶
                    min_conditions = config.get('minConditions', 3)
                    score_threshold = config.get('scoreThreshold', 65)
                    
                    if conditions_met >= min_conditions and rebound_score >= score_threshold:
                        buy_signal = True
                        signal_strength = min(95, rebound_score)
                    
                elif strategy_name == 'trend_enhanced':
                    # è¶‹åŠ¿å¢å¼ºç­–ç•¥ - å‡çº§ç‰ˆï¼šå¤šæ—¶é—´æ¡†æ¶è¶‹åŠ¿ç¡®è®¤
                    conditions_met = 0
                    total_conditions = 0
                    trend_score = 0
                    
                    # 1. çŸ­æœŸå‡çº¿å¤šå¤´æ’åˆ—ï¼ˆå¯é…ç½®å¼€å…³ï¼‰
                    if config.get('useShortMaAlignment', True):
                        total_conditions += 1
                        if d.get('ma5') and d.get('ma10') and d.get('ma20'):
                            if d['ma5'] > d['ma10'] > d['ma20']:
                                conditions_met += 1
                                trend_score += 25
                                # å®Œå…¨å¤šå¤´æ’åˆ—åŠ åˆ†
                                if d.get('ma60') and d['ma20'] > d['ma60']:
                                    trend_score += 10
                    
                    # 2. ä»·æ ¼ç›¸å¯¹å‡çº¿ä½ç½®ï¼ˆå¯é…ç½®å¼€å…³ï¼‰
                    if config.get('usePriceAboveMa', True):
                        total_conditions += 1
                        price_above_count = 0
                        for ma in ['ma5', 'ma10', 'ma20']:
                            if d.get(ma) and d['close'] > d[ma]:
                                price_above_count += 1
                        if price_above_count >= 2:
                            conditions_met += 1
                            trend_score += 15 + price_above_count * 3
                    
                    # 3. MACDæ­£å‘ä¸”åŠ¨èƒ½å¢å¼ºï¼ˆå¯é…ç½®å¼€å…³ï¼‰
                    if config.get('useMacdPositive', True):
                        total_conditions += 1
                        macd_threshold = config.get('macdThreshold', 0)
                        if d.get('macd') and d['macd'] > macd_threshold:
                            conditions_met += 1
                            trend_score += 15
                            # MACDæŸ±çŠ¶å›¾æ‰©å¤§
                            if d.get('macdHist') and prev.get('macdHist') and d['macdHist'] > prev['macdHist']:
                                trend_score += 10
                            # DIFä¸Šç©¿DEAé‡‘å‰
                            if d.get('macdHist') and prev.get('macdHist'):
                                if d['macdHist'] > 0 and prev['macdHist'] <= 0:
                                    trend_score += 15
                    
                    # 4. ADXè¶‹åŠ¿å¼ºåº¦ç¡®è®¤ï¼ˆæ–°å¢ï¼‰
                    if config.get('useAdxConfirm', True):
                        total_conditions += 1
                        if d.get('adx'):
                            if d['adx'] > 25:  # å¼ºè¶‹åŠ¿
                                conditions_met += 1
                                trend_score += 15
                                if d['adx'] > 40:  # æå¼ºè¶‹åŠ¿
                                    trend_score += 10
                            # è¶‹åŠ¿æ–¹å‘ç¡®è®¤
                            if d.get('plus_di') and d.get('minus_di') and d['plus_di'] > d['minus_di']:
                                trend_score += 10
                    
                    # 5. æˆäº¤é‡è¶‹åŠ¿ç¡®è®¤ï¼ˆå¯é…ç½®å¼€å…³ï¼‰
                    if config.get('useVolumeConfirm', True):
                        total_conditions += 1
                        if d.get('volMa5') and d.get('volMa10'):
                            if d['volMa5'] > d['volMa10']:  # æˆäº¤é‡å‡çº¿ä¸Šå‡
                                conditions_met += 1
                                trend_score += 10
                            # é‡ä»·é…åˆ
                            if d['volume'] > d['volMa5'] and d['close'] > d['open']:
                                trend_score += 5
                    
                    # 6. å¸ƒæ—å¸¦è¶‹åŠ¿ç¡®è®¤ï¼ˆå¯é…ç½®å¼€å…³ï¼‰
                    if config.get('useBollConfirm', True):
                        # ä»·æ ¼åœ¨ä¸­è½¨ä¸Šæ–¹
                        if d.get('bollMid') and d['close'] > d['bollMid']:
                            trend_score += 10
                        # å¸ƒæ—å¸¦å¼€å£å‘ä¸Š
                        if d.get('bollWidth') and prev.get('bollWidth') and d['bollWidth'] > prev['bollWidth']:
                            trend_score += 5
                    
                    # 7. ä»·æ ¼åŠ¨é‡ç¡®è®¤ï¼ˆå¯é…ç½®å¼€å…³ï¼‰
                    if config.get('useMomentumConfirm', True):
                        if i >= 10:
                            price_change_10d = (d['close'] - df.iloc[i-10]['close']) / df.iloc[i-10]['close'] * 100
                            if price_change_10d > 5:  # 10æ—¥æ¶¨å¹…è¶…è¿‡5%
                                trend_score += 10
                            if price_change_10d > 10:  # 10æ—¥æ¶¨å¹…è¶…è¿‡10%
                                trend_score += 5
                    
                    # 8. è¶‹åŠ¿æŒç»­æ€§æ£€æŸ¥ - é¿å…å‡çªç ´
                    if config.get('useTrendPersistence', True):
                        if i >= 5:
                            # æ£€æŸ¥è¿‡å»5å¤©æ˜¯å¦æ•´ä½“å‘ä¸Š
                            recent_prices = [df.iloc[j]['close'] for j in range(i-4, i+1)]
                            higher_count = sum(1 for j in range(1, len(recent_prices)) if recent_prices[j] > recent_prices[j-1])
                            if higher_count >= 3:  # è‡³å°‘3å¤©ä¸Šæ¶¨
                                trend_score += 10
                    
                    # åŠ¨æ€ä¹°å…¥æ¡ä»¶
                    min_conditions = config.get('minConditions', 3)
                    score_threshold = config.get('scoreThreshold', 70)
                    
                    if conditions_met >= min_conditions and trend_score >= score_threshold:
                        buy_signal = True
                        signal_strength = min(95, trend_score)
                    
                elif strategy_name == 'macd_divergence':
                    # MACDèƒŒç¦»ç­–ç•¥ - å‡çº§ç‰ˆï¼šå¤šå‘¨æœŸèƒŒç¦»æ£€æµ‹ + ç¡®è®¤æœºåˆ¶
                    divergence_score = 0
                    conditions_met = 0
                    
                    # éœ€è¦è¶³å¤Ÿçš„å†å²æ•°æ®
                    lookback_period = config.get('lookbackPeriod', 30)
                    if i < lookback_period * 2:
                        continue
                    
                    # 1. åº•èƒŒç¦»æ£€æµ‹ï¼ˆæ ¸å¿ƒï¼‰- ä»·æ ¼åˆ›æ–°ä½ä½†MACDæœªåˆ›æ–°ä½
                    if config.get('useBullishDivergence', True):
                        # å¯»æ‰¾è¿‘æœŸä½ç‚¹
                        recent_lows_price = []
                        recent_lows_macd = []
                        
                        for j in range(i - lookback_period, i + 1):
                            if j < 2:
                                continue
                            # å±€éƒ¨ä½ç‚¹åˆ¤æ–­
                            if (df.iloc[j]['close'] < df.iloc[j-1]['close'] and 
                                df.iloc[j]['close'] < df.iloc[j-2]['close'] and
                                df.iloc[j]['close'] < df.iloc[j+1]['close'] if j < len(df) - 1 else True):
                                recent_lows_price.append((j, df.iloc[j]['close'], df.iloc[j]['macd']))
                        
                        # æ£€æµ‹èƒŒç¦»
                        if len(recent_lows_price) >= 2:
                            # æ¯”è¾ƒæœ€è¿‘ä¸¤ä¸ªä½ç‚¹
                            latest_low = recent_lows_price[-1]
                            prev_low = recent_lows_price[-2]
                            
                            # ä»·æ ¼åˆ›æ–°ä½ä½†MACDæœªåˆ›æ–°ä½ï¼ˆåº•èƒŒç¦»ï¼‰
                            if latest_low[1] < prev_low[1] and latest_low[2] > prev_low[2]:
                                conditions_met += 1
                                divergence_score += 40
                                # MACDåœ¨é›¶è½´é™„è¿‘æˆ–ä¸‹æ–¹ï¼ˆæ›´å®‰å…¨ï¼‰
                                if latest_low[2] < 0.5:
                                    divergence_score += 10
                    
                    # 2. MACDæŸ±çŠ¶å›¾èƒŒç¦»æ£€æµ‹
                    if config.get('useHistogramDivergence', True):
                        if i >= 10:
                            price_change = (d['close'] - df.iloc[i-10]['close']) / df.iloc[i-10]['close'] * 100
                            hist_change = d.get('macdHist', 0) - df.iloc[i-10].get('macdHist', 0)
                            
                            # ä»·æ ¼è·Œä½†æŸ±çŠ¶å›¾ä¸Šå‡
                            if price_change < -5 and hist_change > 0:
                                conditions_met += 1
                                divergence_score += 20
                    
                    # 3. æˆäº¤é‡èƒŒç¦»ç¡®è®¤
                    if config.get('useVolumeDivergence', True):
                        if i >= 10:
                            price_low_now = d['close'] < df.iloc[i-10:i]['close'].min()
                            vol_now = d['volume']
                            vol_prev_low = df.iloc[i-5]['volume'] if i >= 5 else vol_now
                            
                            # ä»·æ ¼æ–°ä½ä½†æˆäº¤é‡èç¼©ï¼ˆå–å‹å‡è½»ï¼‰
                            if price_low_now and vol_now < vol_prev_low * 0.8:
                                divergence_score += 15
                                conditions_met += 1
                    
                    # 4. RSIèƒŒç¦»ç¡®è®¤
                    if config.get('useRsiDivergence', True):
                        if i >= lookback_period:
                            recent_lows_rsi = []
                            for j in range(i - lookback_period, i + 1):
                                if j < 2:
                                    continue
                                if df.iloc[j]['rsi'] < 40:  # è¶…å–åŒºåŸŸ
                                    if (df.iloc[j]['rsi'] < df.iloc[j-1]['rsi'] and 
                                        df.iloc[j]['rsi'] < df.iloc[j+1]['rsi'] if j < len(df) - 1 else True):
                                        recent_lows_rsi.append((j, df.iloc[j]['close'], df.iloc[j]['rsi']))
                            
                            if len(recent_lows_rsi) >= 2:
                                latest_rsi_low = recent_lows_rsi[-1]
                                prev_rsi_low = recent_lows_rsi[-2]
                                
                                # ä»·æ ¼åˆ›æ–°ä½ä½†RSIæœªåˆ›æ–°ä½
                                if latest_rsi_low[1] < prev_rsi_low[1] and latest_rsi_low[2] > prev_rsi_low[2]:
                                    divergence_score += 20
                                    conditions_met += 1
                    
                    # 5. è¶‹åŠ¿å¼ºåº¦è¿‡æ»¤ - é¿å…åœ¨æå¼ºä¸‹è·Œè¶‹åŠ¿ä¸­äº¤æ˜“
                    if config.get('useTrendFilter', True):
                        if d.get('adx'):
                            if d['adx'] < 35:  # è¶‹åŠ¿ä¸æ˜¯æå¼º
                                divergence_score += 10
                            # è¶‹åŠ¿å¼€å§‹å‡å¼±
                            if prev.get('adx') and d['adx'] < prev['adx']:
                                divergence_score += 5
                    
                    # 6. Kçº¿å½¢æ€ç¡®è®¤ - çœ‹æ¶¨åè½¬ä¿¡å·
                    if config.get('useCandleConfirm', True):
                        body = d['close'] - d['open']
                        lower_shadow = d['open'] - d['low'] if body > 0 else d['close'] - d['low']
                        body_size = abs(body)
                        
                        # é”¤å­çº¿æˆ–ä¸‹å½±çº¿è¾ƒé•¿
                        if lower_shadow > body_size * 1.5:
                            divergence_score += 10
                        # é˜³çº¿æ”¶ç›˜
                        if d['close'] > d['open']:
                            divergence_score += 5
                    
                    # 7. å‡çº¿ç³»ç»Ÿç¡®è®¤
                    if config.get('useMaConfirm', True):
                        # ä»·æ ¼æ¥è¿‘é‡è¦å‡çº¿æ”¯æ’‘
                        if d.get('ma60') and d['close'] > d['ma60'] * 0.95:
                            divergence_score += 10
                        # çŸ­æœŸå‡çº¿èµ°å¹³æˆ–å‘ä¸Š
                        if d.get('ma5') and prev.get('ma5') and d['ma5'] >= prev['ma5']:
                            divergence_score += 5
                    
                    # åŠ¨æ€ä¹°å…¥æ¡ä»¶
                    min_conditions = config.get('minConditions', 2)
                    score_threshold = config.get('scoreThreshold', 60)
                    
                    if conditions_met >= min_conditions and divergence_score >= score_threshold:
                        buy_signal = True
                        signal_strength = min(95, divergence_score)
                
                elif strategy_name == 'bollinger_extreme':
                    # å¸ƒæ—æé™ç­–ç•¥ - å‡çº§ç‰ˆï¼šå¸ƒæ—å¸¦æå€¼äº¤æ˜“ + åè½¬ç¡®è®¤
                    boll_score = 0
                    conditions_met = 0
                    total_conditions = 0
                    
                    # 1. å¸ƒæ—å¸¦ä¸‹è½¨è§¦åŠï¼ˆå¯é…ç½®å¼€å…³ï¼‰- ä¹°å…¥ä¿¡å·
                    if config.get('useLowerBandTouch', True):
                        total_conditions += 1
                        boll_deviation = config.get('bollDeviation', 2.0)
                        
                        # ä»·æ ¼è§¦åŠæˆ–è·Œç ´ä¸‹è½¨
                        if d.get('bollDown') and d['close'] <= d['bollDown'] * (1 + 0.01):
                            conditions_met += 1
                            boll_score += 30
                            
                            # è®¡ç®—å¸ƒæ—å¸¦ç™¾åˆ†ä½ä½ç½®
                            if d.get('bollUp') and d.get('bollDown') and d['bollUp'] != d['bollDown']:
                                boll_percent = (d['close'] - d['bollDown']) / (d['bollUp'] - d['bollDown']) * 100
                                if boll_percent < 5:  # æ¥è¿‘æœ€åº•éƒ¨
                                    boll_score += 15
                            
                            # ä»ä¸‹è½¨åå¼¹
                            if d['close'] > d['open']:
                                boll_score += 10
                    
                    # 2. å¸ƒæ—å¸¦å®½åº¦ç¡®è®¤ - é¿å…åœ¨æåº¦æ”¶ç¼©æ—¶äº¤æ˜“
                    if config.get('useBandWidthConfirm', True):
                        if d.get('bollWidth'):
                            # å¸ƒæ—å¸¦å®½åº¦é€‚ä¸­ï¼ˆæœ‰æ³¢åŠ¨ä½†ä¸è¿‡åº¦ï¼‰
                            if 0.05 < d['bollWidth'] < 0.25:
                                boll_score += 10
                            # å¸ƒæ—å¸¦ä»æ”¶ç¼©å¼€å§‹æ‰©å¼ ï¼ˆæ³¢åŠ¨ç‡çªç ´ï¼‰
                            if prev.get('bollWidth') and d['bollWidth'] > prev['bollWidth'] * 1.1:
                                boll_score += 10
                                conditions_met += 1
                    
                    # 3. RSIè¶…å–ç¡®è®¤
                    if config.get('useRsiConfirm', True):
                        total_conditions += 1
                        rsi_oversold = config.get('rsiOversold', 30)
                        if d.get('rsi') and d['rsi'] < rsi_oversold:
                            conditions_met += 1
                            boll_score += 20
                            if d['rsi'] < 20:  # ä¸¥é‡è¶…å–
                                boll_score += 10
                            # RSIå¼€å§‹å›å‡
                            if prev.get('rsi') and d['rsi'] > prev['rsi']:
                                boll_score += 5
                    
                    # 4. æˆäº¤é‡ç¡®è®¤ - åœ°é‡æˆ–æ”¾é‡åå¼¹
                    if config.get('useVolumeConfirm', True):
                        total_conditions += 1
                        vol_ratio = d['volume'] / d['volMa5'] if d.get('volMa5') and d['volMa5'] > 0 else 1
                        
                        # åœ°é‡ï¼ˆç¼©é‡è§åº•ï¼‰
                        if vol_ratio < 0.7:
                            conditions_met += 1
                            boll_score += 15
                        # æˆ–è€…æ”¾é‡åå¼¹
                        elif d['close'] > d['open'] and vol_ratio > 1.3:
                            conditions_met += 1
                            boll_score += 15
                    
                    # 5. å‡çº¿æ”¯æ’‘ç¡®è®¤
                    if config.get('useMaSupport', True):
                        # ä»·æ ¼æ¥è¿‘é•¿æœŸå‡çº¿æ”¯æ’‘
                        if d.get('ma60') and d['close'] > d['ma60'] * 0.97:
                            boll_score += 10
                        # çŸ­æœŸå‡çº¿èµ°å¹³
                        if d.get('ma5') and prev.get('ma5') and abs(d['ma5'] - prev['ma5']) / d['ma5'] < 0.005:
                            boll_score += 5
                    
                    # 6. Kçº¿å½¢æ€ç¡®è®¤
                    if config.get('useCandleConfirm', True):
                        body = d['close'] - d['open']
                        lower_shadow = d['open'] - d['low'] if body > 0 else d['close'] - d['low']
                        body_size = abs(body)
                        
                        # ä¸‹å½±çº¿è¾ƒé•¿ï¼ˆæ”¯æ’‘æ˜æ˜¾ï¼‰
                        if lower_shadow > body_size * 1.5:
                            boll_score += 15
                        # é˜³çº¿æ”¶ç›˜
                        if d['close'] > d['open']:
                            boll_score += 5
                        # æ”¶ç›˜ä»·æ¥è¿‘æœ€é«˜ä»·
                        if d['high'] > d['low']:
                            close_position = (d['close'] - d['low']) / (d['high'] - d['low'])
                            if close_position > 0.7:
                                boll_score += 10
                    
                    # 7. æ³¢åŠ¨ç‡è°ƒæ•´
                    if config.get('useVolatilityAdjust', True):
                        if d.get('atr_pct'):
                            # æ ¹æ®ATRè°ƒæ•´è¯„åˆ†
                            if d['atr_pct'] > 3:  # é«˜æ³¢åŠ¨
                                boll_score *= 1.1  # é«˜åˆ†è‚¡ç¥¨å¯èƒ½æœ‰å¤§åå¼¹
                            elif d['atr_pct'] < 1:  # ä½æ³¢åŠ¨
                                boll_score *= 0.9  # ä½æ³¢åŠ¨è‚¡ç¥¨åå¼¹å¯èƒ½è¾ƒå°
                    
                    # åŠ¨æ€ä¹°å…¥æ¡ä»¶
                    min_conditions = config.get('minConditions', 2)
                    score_threshold = config.get('scoreThreshold', 60)
                    
                    if conditions_met >= min_conditions and boll_score >= score_threshold:
                        buy_signal = True
                        signal_strength = min(95, int(boll_score))
                
                elif strategy_name == 'momentum_rotation':
                    # åŠ¨é‡è½®åŠ¨ç­–ç•¥ - å‡çº§ç‰ˆï¼šå¤šå‘¨æœŸåŠ¨é‡ç¡®è®¤ + ç›¸å¯¹å¼ºåº¦åˆ†æ
                    momentum_score = 0
                    conditions_met = 0
                    
                    # 1. çŸ­æœŸåŠ¨é‡ï¼ˆå¯é…ç½®å¼€å…³ï¼‰
                    if config.get('useShortMomentum', True):
                        short_period = int(config.get('shortMomentumPeriod', 10))
                        if i >= short_period:
                            short_momentum = (d['close'] - df.iloc[i-short_period]['close']) / df.iloc[i-short_period]['close'] * 100
                            short_threshold = config.get('shortMomentumThreshold', 3.0)
                            
                            if short_momentum > short_threshold:
                                conditions_met += 1
                                momentum_score += 20
                                if short_momentum > short_threshold * 1.5:
                                    momentum_score += 10
                    
                    # 2. ä¸­æœŸåŠ¨é‡ï¼ˆå¯é…ç½®å¼€å…³ï¼‰
                    if config.get('useMediumMomentum', True):
                        medium_period = int(config.get('mediumMomentumPeriod', 20))
                        if i >= medium_period:
                            medium_momentum = (d['close'] - df.iloc[i-medium_period]['close']) / df.iloc[i-medium_period]['close'] * 100
                            medium_threshold = config.get('mediumMomentumThreshold', 5.0)
                            
                            if medium_momentum > medium_threshold:
                                conditions_met += 1
                                momentum_score += 25
                                # åŠ¨é‡åŠ é€Ÿ
                                if i >= medium_period + 5:
                                    prev_momentum = (df.iloc[i-5]['close'] - df.iloc[i-medium_period-5]['close']) / df.iloc[i-medium_period-5]['close'] * 100
                                    if medium_momentum > prev_momentum:
                                        momentum_score += 10
                    
                    # 3. é•¿æœŸåŠ¨é‡è¶‹åŠ¿ï¼ˆå¯é…ç½®å¼€å…³ï¼‰
                    if config.get('useLongMomentum', True):
                        long_period = int(config.get('longMomentumPeriod', 60))
                        if i >= long_period:
                            long_momentum = (d['close'] - df.iloc[i-long_period]['close']) / df.iloc[i-long_period]['close'] * 100
                            
                            if long_momentum > 0:  # é•¿æœŸè¶‹åŠ¿å‘ä¸Š
                                momentum_score += 15
                                if long_momentum > 10:
                                    momentum_score += 5
                    
                    # 4. ç›¸å¯¹å¼ºåº¦ - ä¸å¤§ç›˜æ¯”è¾ƒï¼ˆç®€åŒ–ç‰ˆï¼Œä½¿ç”¨å‡çº¿ï¼‰
                    if config.get('useRelativeStrength', True):
                        if d.get('ma5') and d.get('ma20') and d.get('ma60'):
                            # ä»·æ ¼ç›¸å¯¹å‡çº¿çš„ä½ç½®
                            price_vs_ma20 = (d['close'] - d['ma20']) / d['ma20'] * 100
                            ma20_vs_ma60 = (d['ma20'] - d['ma60']) / d['ma60'] * 100
                            
                            if price_vs_ma20 > 0 and ma20_vs_ma60 > 0:
                                momentum_score += 15
                                if price_vs_ma20 > 5:
                                    momentum_score += 5
                    
                    # 5. æˆäº¤é‡ç¡®è®¤ï¼ˆå¯é…ç½®å¼€å…³ï¼‰
                    if config.get('useVolumeConfirm', True):
                        vol_multi = float(config.get('volumeMulti', 1.5))
                        vol_ratio = d['volume'] / d['volMa5'] if d.get('volMa5') and d['volMa5'] > 0 else 1
                        
                        if vol_ratio > vol_multi:
                            conditions_met += 1
                            momentum_score += 15
                            # æˆäº¤é‡æŒç»­æ”¾å¤§
                            if d.get('volMa5') and d.get('volMa10') and d['volMa5'] > d['volMa10']:
                                momentum_score += 5
                        # é‡ä»·é…åˆ
                        if d['close'] > d['open'] and vol_ratio > 1:
                            momentum_score += 5
                    
                    # 6. åŠ¨é‡è´¨é‡ - é¿å…è¿‡åº¦å»¶ä¼¸
                    if config.get('useMomentumQuality', True):
                        if i >= 20:
                            recent_returns = []
                            for j in range(i-19, i+1):
                                if j > 0:
                                    daily_return = (df.iloc[j]['close'] - df.iloc[j-1]['close']) / df.iloc[j-1]['close'] * 100
                                    recent_returns.append(daily_return)
                            
                            if recent_returns:
                                avg_return = sum(recent_returns) / len(recent_returns)
                                max_return = max(recent_returns)
                                
                                # å¹³å‡æ”¶ç›Šä¸ºæ­£ä¸”æ²¡æœ‰æç«¯å¤§æ¶¨
                                if avg_return > 0.3 and max_return < 10:
                                    momentum_score += 10
                                # è¿ç»­ä¸Šæ¶¨å¤©æ•°
                                up_days = sum(1 for r in recent_returns if r > 0)
                                if up_days >= 12:  # 20å¤©ä¸­è‡³å°‘12å¤©ä¸Šæ¶¨
                                    momentum_score += 5
                    
                    # 7. æ³¢åŠ¨ç‡è°ƒæ•´ - åŠ¨é‡ä¸æ³¢åŠ¨ç‡åŒ¹é…
                    if config.get('useVolatilityAdjust', True):
                        if d.get('atr_pct'):
                            # é€‚ä¸­çš„æ³¢åŠ¨ç‡æœ‰åˆ©äºåŠ¨é‡å»¶ç»­
                            if 1.5 < d['atr_pct'] < 4:
                                momentum_score += 10
                            elif d['atr_pct'] > 5:  # æ³¢åŠ¨è¿‡å¤§ï¼ŒåŠ¨é‡å¯èƒ½ä¸ç¨³å®š
                                momentum_score -= 5
                    
                    # 8. MACDåŠ¨é‡ç¡®è®¤
                    if config.get('useMacdConfirm', True):
                        if d.get('macd') and d['macd'] > 0:
                            momentum_score += 10
                            if d.get('macdHist') and prev.get('macdHist'):
                                if d['macdHist'] > prev['macdHist']:  # åŠ¨é‡å¢å¼º
                                    momentum_score += 5
                    
                    # åŠ¨æ€ä¹°å…¥æ¡ä»¶
                    min_conditions = config.get('minConditions', 3)
                    score_threshold = config.get('scoreThreshold', 65)
                    
                    if conditions_met >= min_conditions and momentum_score >= score_threshold:
                        buy_signal = True
                        signal_strength = min(95, momentum_score)
                
                elif strategy_name == 'turtle_enhanced':
                    # æµ·é¾Ÿå¢å¼ºç­–ç•¥ - å‡çº§ç‰ˆï¼šå¤šæ—¶é—´æ¡†æ¶çªç ´ + é£é™©ç®¡ç†å¢å¼º
                    turtle_score = 0
                    conditions_met = 0
                    
                    entry_period = int(config.get('entryPeriod', 20))
                    exit_period = int(config.get('exitPeriod', 10))
                    atr_multiplier = float(config.get('atrMultiplier', 2.0))
                    
                    if i < entry_period:
                        continue
                    
                    # 1. çªç ´å…¥åœºæ¡ä»¶ï¼ˆæ ¸å¿ƒï¼‰- å¤šå‘¨æœŸçªç ´ç¡®è®¤
                    if config.get('useBreakoutEntry', True):
                        # 20æ—¥é«˜ç‚¹çªç ´
                        if d.get('high20') and d['close'] >= d['high20'] * 0.995:
                            conditions_met += 1
                            turtle_score += 30
                            
                            # åŒæ—¶çªç ´60æ—¥é«˜ç‚¹ï¼ˆå¼ºè¶‹åŠ¿ï¼‰
                            if d.get('high60') and d['close'] >= d['high60']:
                                turtle_score += 15
                            
                            # çªç ´å¹…åº¦
                            breakout_pct = (d['close'] - d['high20']) / d['high20'] * 100 if d['high20'] > 0 else 0
                            if 0 < breakout_pct < 3:  # é€‚ä¸­çªç ´ï¼Œé¿å…è¿‡åº¦å»¶ä¼¸
                                turtle_score += 5
                    
                    # 2. è¶‹åŠ¿è¿‡æ»¤ - åªåœ¨è¶‹åŠ¿æ˜ç¡®æ—¶äº¤æ˜“
                    if config.get('useTrendFilter', True):
                        if d.get('ma20') and d.get('ma60'):
                            if d['close'] > d['ma20'] > d['ma60']:  # å¤šå¤´æ’åˆ—
                                conditions_met += 1
                                turtle_score += 15
                                if d.get('ma5') and d['ma5'] > d['ma20']:
                                    turtle_score += 5
                    
                    # 3. æ³¢åŠ¨ç‡è¿‡æ»¤ - ATRç¡®è®¤
                    if config.get('useVolatilityFilter', True):
                        if d.get('atr_pct'):
                            # é€‚ä¸­çš„æ³¢åŠ¨ç‡
                            if 1.5 < d['atr_pct'] < 5:
                                turtle_score += 10
                                conditions_met += 1
                            # æ³¢åŠ¨ç‡ä¸èƒ½è¿‡ä½ï¼ˆé¿å…æ— æ³¢åŠ¨å¸‚åœºï¼‰
                            if d['atr_pct'] > 1:
                                turtle_score += 5
                    
                    # 4. æˆäº¤é‡ç¡®è®¤ - çªç ´éœ€è¦é‡èƒ½é…åˆ
                    if config.get('useVolumeConfirm', True):
                        vol_multi = config.get('volumeMulti', 1.5)
                        vol_ratio = d['volume'] / d['volMa5'] if d.get('volMa5') and d['volMa5'] > 0 else 1
                        
                        if vol_ratio > vol_multi:
                            conditions_met += 1
                            turtle_score += 15
                            # æˆäº¤é‡æŒç»­æ”¾å¤§
                            if d.get('volMa5') and d.get('volMa10') and d['volMa5'] > d['volMa10']:
                                turtle_score += 5
                    
                    # 5. ADXè¶‹åŠ¿å¼ºåº¦ç¡®è®¤
                    if config.get('useAdxConfirm', True):
                        if d.get('adx'):
                            if d['adx'] > 25:  # è¶‹åŠ¿å¸‚åœº
                                turtle_score += 15
                                conditions_met += 1
                                if d['adx'] > 35:  # å¼ºè¶‹åŠ¿
                                    turtle_score += 10
                            # è¶‹åŠ¿æ–¹å‘
                            if d.get('plus_di') and d.get('minus_di') and d['plus_di'] > d['minus_di']:
                                turtle_score += 5
                    
                    # 6. å‡çªç ´è¿‡æ»¤ - é¿å…éœ‡è¡å¸‚å‡ä¿¡å·
                    if config.get('useFalseBreakoutFilter', True):
                        if i >= entry_period + 5:
                            # æ£€æŸ¥ä¹‹å‰æ˜¯å¦æœ‰å¤šæ¬¡å‡çªç ´
                            recent_highs = [df.iloc[j]['high20'] for j in range(i-entry_period, i) if df.iloc[j].get('high20')]
                            if recent_highs:
                                avg_high20 = sum(recent_highs) / len(recent_highs)
                                # å¦‚æœå½“å‰çªç ´æ˜æ˜¾é«˜äºä¹‹å‰çš„éœ‡è¡åŒºé—´
                                if d['close'] > avg_high20 * 1.02:
                                    turtle_score += 10
                    
                    # 7. é£é™©ç®¡ç†è¯„åˆ† - åŸºäºATRçš„ä»“ä½ç®¡ç†
                    if config.get('useRiskManagement', True):
                        if d.get('atr') and d['close'] > 0:
                            risk_pct = d['atr'] / d['close'] * 100
                            if risk_pct < 3:  # é£é™©é€‚ä¸­
                                turtle_score += 10
                            elif risk_pct > 5:  # é£é™©è¿‡é«˜ï¼Œé™ä½è¯„åˆ†
                                turtle_score -= 10
                    
                    # 8. å¸‚åœºæƒ…ç»ª - é¿å…è¿‡åº¦ä¹è§‚
                    if config.get('useSentimentFilter', True):
                        if d.get('rsi'):
                            if d['rsi'] < 70:  # æœªè¿‡åº¦ä¹°å…¥
                                turtle_score += 5
                            if d['rsi'] < 60:  # è¿˜æœ‰ä¸Šæ¶¨ç©ºé—´
                                turtle_score += 5
                    
                    # åŠ¨æ€ä¹°å…¥æ¡ä»¶
                    min_conditions = config.get('minConditions', 3)
                    score_threshold = config.get('scoreThreshold', 65)
                    
                    if conditions_met >= min_conditions and turtle_score >= score_threshold:
                        buy_signal = True
                        signal_strength = min(95, turtle_score)
                        
                        # è®¡ç®—æ­¢æŸä»·ï¼ˆç”¨äºåç»­é£é™©ç®¡ç†ï¼‰
                        atr = d.get('atr', abs(d['high'] - d['low']) * 0.5)
                        stop_price = d['close'] - atr * atr_multiplier
            
            # å–å‡ºé€»è¾‘ - ä¼˜åŒ–ç‰ˆï¼Œæ”¯æŒæ›´å¤šå¯é…ç½®æ¡ä»¶
            if position > 0:
                highest_since_entry = max(highest_since_entry, d['high'])
                hold_days = i - entry_index
                profit = (d['close'] - entry_price) / entry_price
                
                # æ­¢æŸï¼ˆå¯é…ç½®å¼€å…³ï¼‰
                if config.get('useStopLoss', True):
                    stop_loss_level = config.get('stopLoss', 0.08)
                    if profit <= -stop_loss_level:
                        sell_signal = True
                        sell_reason = 'æ­¢æŸ'
                
                # æ­¢ç›ˆï¼ˆå¯é…ç½®å¼€å…³ï¼‰
                elif config.get('useTakeProfit', True):
                    take_profit_level = config.get('takeProfit', 0.15)
                    if profit >= take_profit_level:
                        sell_signal = True
                        sell_reason = 'æ­¢ç›ˆ'
                
                # è·Œç ´MA5ï¼ˆå¯é…ç½®å¼€å…³ï¼‰
                elif config.get('useMa5Sell', True):
                    if d.get('ma5') and d['close'] < d['ma5'] and profit > 0.02:
                        sell_signal = True
                        sell_reason = 'è·Œç ´MA5'
                
                # åŠ¨æ€æ­¢ç›ˆï¼ˆå¯é…ç½®å¼€å…³ï¼‰
                elif config.get('useDynamicTP', True):
                    dtp_threshold = config.get('dynamicTpThreshold', 0.08)
                    dtp_callback = config.get('dynamicTpCallback', 0.03)
                    dtp_variation = config.get('dynamicTpVariation', 0.15)
                    
                    if profit > dtp_threshold:
                        trail = highest_since_entry * (1 - dtp_callback - profit * dtp_variation)
                        if d['close'] < trail:
                            sell_signal = True
                            sell_reason = 'ç§»åŠ¨æ­¢ç›ˆ'
                
                # MACDæ­»å‰ï¼ˆå¯é…ç½®å¼€å…³ï¼‰
                elif config.get('useMacdDeathCross', True):
                    if d.get('macd') and prev.get('macd') and d['macd'] < 0 and prev['macd'] > 0 and profit > 0:
                        sell_signal = True
                        sell_reason = 'MACDæ­»å‰'
                
                # RSIè¶…ä¹°ï¼ˆå¯é…ç½®å¼€å…³ï¼‰
                elif config.get('useRsiOverbought', True):
                    if d.get('rsi') and d['rsi'] > 80 and profit > 0.05:
                        sell_signal = True
                        sell_reason = 'RSIè¶…ä¹°'
                
                # æŒä»“è¶…æ—¶ï¼ˆå¯é…ç½®å¼€å…³ï¼‰
                elif config.get('useHoldTimeout', True):
                    hold_timeout_days = config.get('holdTimeoutDays', 30)
                    if hold_days > hold_timeout_days and profit < 0.05:
                        sell_signal = True
                        sell_reason = 'æŒä»“è¶…æ—¶'
            
            # è®°å½•ä¿¡å·
            if buy_signal and position == 0:
                # åŠ¨æ€ä»“ä½ç®¡ç†
                if config.get('useAdaptPosition', True):
                    # ä¿¡å·å¼ºåº¦è¶Šé«˜ï¼Œä»“ä½è¶Šå¤§
                    base_position = 0.3
                    strength_factor = signal_strength / 100
                    position = base_position + strength_factor * 0.7
                    # æ ¹æ®å¸‚åœºçŠ¶æ€è°ƒæ•´
                    if market_state in ['bear_market', 'choppy_market']:
                        position *= 0.8  # ç†Šå¸‚/éœ‡è¡å¸‚é™ä½ä»“ä½
                    position = min(position, 1.0)  # ä¸è¶…è¿‡100%
                else:
                    position = 1.0
                
                entry_price = d['close']
                entry_index = i
                highest_since_entry = d['high']
                
                signals.append({
                    'index': i,
                    'date': d['date'],
                    'type': 'buy',
                    'price': float(d['close']),
                    'position': position,
                    'strength': signal_strength
                })
            
            if sell_signal and position > 0:
                profit_pct = ((d['close'] - entry_price) / entry_price) * 100
                signals.append({
                    'index': i,
                    'date': d['date'],
                    'type': 'sell',
                    'price': float(d['close']),
                    'position': position,
                    'profit': profit_pct,
                    'holdDays': i - entry_index,
                    'reason': sell_reason,
                    'strength': signal_strength
                })
                position = 0
                last_sell_index = i  # æ›´æ–°å–å‡ºç´¢å¼•
        
        return signals
    
    @staticmethod
    def calculate_backtest(data, signals, init_capital):
        """è®¡ç®—å›æµ‹ç»“æœ"""
        df = pd.DataFrame(data)
        capital = init_capital
        shares = 0
        position = 0
        equity = [init_capital]
        
        wins = 0
        losses = 0
        total_profit = 0
        total_loss = 0
        hold_days_sum = 0
        trades = []
        
        signal_dict = {s['index']: s for s in signals}
        
        for i in range(len(df)):
            signal = signal_dict.get(i)
            
            if signal:
                if signal['type'] == 'buy':
                    amount = capital * signal['position'] * 0.998
                    shares = int(amount / signal['price'] / 100) * 100
                    capital -= shares * signal['price'] * 1.001
                    position = signal['position']
                    trades.append({**signal, 'shares': shares, 'amount': shares * signal['price']})
                else:
                    sell_amount = shares * signal['price'] * 0.998
                    capital += sell_amount
                    
                    if signal.get('profit', 0) > 0:
                        wins += 1
                        total_profit += signal['profit']
                    else:
                        losses += 1
                        total_loss += abs(signal.get('profit', 0))
                    
                    hold_days_sum += signal.get('holdDays', 0)
                    trades.append({**signal, 'shares': shares, 'amount': sell_amount})
                    shares = 0
                    position = 0
            
            current_value = capital + shares * df.iloc[i]['close']
            equity.append(current_value)
        
        final_equity = capital + shares * df.iloc[-1]['close']
        total_return = ((final_equity - init_capital) / init_capital) * 100
        days = len(df)
        annual_return = (pow(1 + total_return / 100, 252 / days) - 1) * 100 if days > 0 else 0
        
        # æœ€å¤§å›æ’¤
        max_drawdown = 0
        peak = equity[0]
        for e in equity:
            peak = max(peak, e)
            drawdown = (peak - e) / peak * 100 if peak > 0 else 0
            max_drawdown = max(max_drawdown, drawdown)
        
        # å¤æ™®æ¯”ç‡
        returns = []
        for i in range(1, len(equity)):
            if equity[i-1] > 0:
                returns.append((equity[i] - equity[i-1]) / equity[i-1])
        
        if returns:
            avg_return = np.mean(returns)
            std_return = np.std(returns)
            sharpe = (avg_return * 252 - 0.03) / (std_return * np.sqrt(252)) if std_return > 0 else 0
        else:
            sharpe = 0
        
        win_rate = (wins / (wins + losses)) * 100 if (wins + losses) > 0 else 0
        profit_ratio = total_profit / total_loss if total_loss > 0 else (10 if total_profit > 0 else 0)
        calmar = annual_return / max_drawdown if max_drawdown > 0 else 0
        avg_hold_days = hold_days_sum / (wins + losses) if (wins + losses) > 0 else 0
        
        # ç»¼åˆè¯„åˆ†
        score = (
            min(total_return / 2, 30) +
            min(sharpe * 10, 25) +
            max(0, 25 - max_drawdown) +
            min(win_rate / 4, 20)
        )
        
        return {
            'initCapital': init_capital,
            'finalCapital': final_equity,
            'totalReturn': total_return,
            'annualReturn': annual_return,
            'maxDrawdown': max_drawdown,
            'sharpe': sharpe,
            'calmar': calmar,
            'winRate': win_rate,
            'profitRatio': profit_ratio,
            'avgHoldDays': avg_hold_days,
            'wins': wins,
            'losses': losses,
            'trades': trades,
            'equity': equity,
            'score': score,
            'tradeCount': wins + losses
        }


def calculate_indicators(df):
    """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡"""
    if df is None or len(df) == 0:
        return df
    
    # è½¬æ¢ä¸ºDataFrameï¼ˆå¦‚æœæ˜¯å­—å…¸åˆ—è¡¨ï¼‰
    if isinstance(df, list):
        df = pd.DataFrame(df)
    
    # åŸºç¡€æŒ‡æ ‡
    df['ma5'] = df['close'].rolling(window=5).mean()
    df['ma10'] = df['close'].rolling(window=10).mean()
    df['ma20'] = df['close'].rolling(window=20).mean()
    df['ma30'] = df['close'].rolling(window=30).mean()
    df['ma60'] = df['close'].rolling(window=60).mean()
    
    # æˆäº¤é‡å‡çº¿
    df['volMa5'] = df['volume'].rolling(window=5).mean()
    df['volMa10'] = df['volume'].rolling(window=10).mean()
    df['volMa20'] = df['volume'].rolling(window=20).mean()
    
    # RSI
    delta = df['close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['rsi'] = 100 - (100 / (1 + rs))
    
    # MACD
    exp12 = df['close'].ewm(span=12, adjust=False).mean()
    exp26 = df['close'].ewm(span=26, adjust=False).mean()
    df['macd'] = exp12 - exp26
    df['macdSignal'] = df['macd'].ewm(span=9, adjust=False).mean()
    df['macdHist'] = df['macd'] - df['macdSignal']
    
    # å¸ƒæ—å¸¦
    df['bollMid'] = df['close'].rolling(window=20).mean()
    boll_std = df['close'].rolling(window=20).std()
    df['bollUp'] = df['bollMid'] + 2 * boll_std
    df['bollDown'] = df['bollMid'] - 2 * boll_std
    df['bollWidth'] = (df['bollUp'] - df['bollDown']) / df['bollMid']  # å¸ƒæ—å¸¦å®½åº¦
    
    # é«˜ä½ç‚¹
    df['high10'] = df['high'].rolling(window=10).max()
    df['low10'] = df['low'].rolling(window=10).min()
    df['high20'] = df['high'].rolling(window=20).max()
    df['low20'] = df['low'].rolling(window=20).min()
    df['high60'] = df['high'].rolling(window=60).max()
    df['low60'] = df['low'].rolling(window=60).min()
    
    # ATR (Average True Range)
    df['tr1'] = df['high'] - df['low']
    df['tr2'] = abs(df['high'] - df['close'].shift(1))
    df['tr3'] = abs(df['low'] - df['close'].shift(1))
    df['tr'] = df[['tr1', 'tr2', 'tr3']].max(axis=1)
    df['atr'] = df['tr'].rolling(window=14).mean()
    df['atr_pct'] = df['atr'] / df['close'] * 100  # ATRç™¾åˆ†æ¯”
    
    # ADX (Average Directional Index) - è¶‹åŠ¿å¼ºåº¦
    df['plus_dm'] = df['high'].diff()
    df['minus_dm'] = -df['low'].diff()
    df['plus_dm'] = df['plus_dm'].where((df['plus_dm'] > 0) & (df['plus_dm'] > df['minus_dm']), 0)
    df['minus_dm'] = df['minus_dm'].where((df['minus_dm'] > 0) & (df['minus_dm'] > df['plus_dm']), 0)
    df['plus_di'] = 100 * (df['plus_dm'].rolling(window=14).mean() / df['atr'])
    df['minus_di'] = 100 * (df['minus_dm'].rolling(window=14).mean() / df['atr'])
    df['dx'] = 100 * abs(df['plus_di'] - df['minus_di']) / (df['plus_di'] + df['minus_di'])
    df['adx'] = df['dx'].rolling(window=14).mean()
    
    # é‡èƒ½åˆ†å¸ƒåˆ†æ
    df['vol_percentile'] = df['volume'].rank(pct=True) * 100
    
    # ä»·æ ¼ä½ç½®åˆ†æ
    df['price_position_20'] = (df['close'] - df['low20']) / (df['high20'] - df['low20']) * 100
    df['price_position_60'] = (df['close'] - df['low60']) / (df['high60'] - df['low60']) * 100
    
    return df


def identify_market_state(df):
    """è¯†åˆ«å¸‚åœºçŠ¶æ€ - å¢å¼ºç‰ˆ"""
    if df is None or len(df) < 60:
        return 'unknown'
    
    # è½¬æ¢ä¸ºDataFrameï¼ˆå¦‚æœæ˜¯å­—å…¸åˆ—è¡¨ï¼‰
    if isinstance(df, list):
        df = pd.DataFrame(df)
    
    latest = df.iloc[-1]
    recent = df.tail(20)
    
    # è¶‹åŠ¿åˆ¤æ–­ (ä½¿ç”¨ADXå¢å¼º)
    adx_strength = latest['adx'] if 'adx' in latest else 0
    ma_trend = 'neutral'
    
    if latest['ma5'] > latest['ma20'] and latest['ma20'] > latest['ma60']:
        ma_trend = 'strong_uptrend'
    elif latest['ma5'] > latest['ma20']:
        ma_trend = 'weak_uptrend'
    elif latest['ma5'] < latest['ma20'] and latest['ma20'] < latest['ma60']:
        ma_trend = 'strong_downtrend'
    elif latest['ma5'] < latest['ma20']:
        ma_trend = 'weak_downtrend'
    
    # æ³¢åŠ¨æ€§åˆ¤æ–­ (ä½¿ç”¨å¸ƒæ—å¸¦å®½åº¦å’ŒATR)
    boll_width = latest['bollWidth'] if 'bollWidth' in latest else 0
    atr_volatility = latest['atr_pct'] if 'atr_pct' in latest else 0
    
    if boll_width > 0.15 or atr_volatility > 3:
        volatility_state = 'high'
    elif boll_width > 0.08 or atr_volatility > 1.5:
        volatility_state = 'medium'
    else:
        volatility_state = 'low'
    
    # é‡èƒ½çŠ¶æ€
    vol_state = 'normal'
    if latest['vol_percentile'] > 80:
        vol_state = 'high_volume'
    elif latest['vol_percentile'] < 20:
        vol_state = 'low_volume'
    
    # ç»¼åˆå¸‚åœºçŠ¶æ€åˆ¤æ–­
    if ma_trend == 'strong_uptrend' and volatility_state in ['medium', 'low']:
        return 'bull_market'
    elif ma_trend == 'strong_downtrend' and volatility_state == 'high':
        return 'bear_market'
    elif ma_trend in ['weak_uptrend', 'weak_downtrend'] and volatility_state == 'high':
        return 'volatile_market'
    elif ma_trend == 'neutral' and volatility_state == 'low':
        return 'sideways_market'
    elif ma_trend == 'neutral' and volatility_state == 'high':
        return 'choppy_market'
    else:
        return f'{ma_trend}_{volatility_state}'


def calculate_signal_strength(data, strategy_name, signals, market_state):
    """è®¡ç®—ä¿¡å·å¼ºåº¦ - å¤šå› å­ç»¼åˆè¯„åˆ†"""
    if not signals or len(signals) == 0:
        return signals
    
    df = pd.DataFrame(data)
    if len(df) < 20:
        return signals
    
    # å¸‚åœºçŠ¶æ€æƒé‡
    market_weights = {
        'bull_market': {'trend': 1.2, 'momentum': 1.1, 'volatility': 0.8},
        'bear_market': {'trend': 0.7, 'momentum': 0.8, 'volatility': 1.3},
        'sideways_market': {'trend': 0.8, 'momentum': 1.2, 'volatility': 1.0},
        'volatile_market': {'trend': 0.9, 'momentum': 1.3, 'volatility': 1.1},
        'choppy_market': {'trend': 0.6, 'momentum': 0.9, 'volatility': 1.2}
    }
    
    base_weight = market_weights.get(market_state, {'trend': 1.0, 'momentum': 1.0, 'volatility': 1.0})
    
    # ç­–ç•¥ç‰¹å®šçš„å› å­æƒé‡
    strategy_factors = {
        'deep_fusion': {'ma_alignment': 0.2, 'macd_momentum': 0.2, 'rsi_condition': 0.15, 'volume_confirmation': 0.15, 'bollinger_position': 0.1, 'price_momentum': 0.1, 'volatility_adjustment': 0.1},
        'volume_breakout': {'breakout_strength': 0.3, 'volume_surge': 0.3, 'trend_alignment': 0.2, 'volatility_filter': 0.2},
        'oversold_rebound': {'oversold_level': 0.3, 'support_confirmation': 0.25, 'volume_confirmation': 0.2, 'trend_reversal': 0.15, 'volatility_adjustment': 0.1},
        'trend_enhanced': {'trend_strength': 0.35, 'ma_alignment': 0.25, 'momentum_confirmation': 0.2, 'volatility_filter': 0.2},
        'macd_divergence': {'divergence_quality': 0.3, 'trend_confirmation': 0.25, 'volume_support': 0.2, 'price_position': 0.15, 'volatility_adjustment': 0.1},
        'bollinger_extreme': {'extreme_level': 0.35, 'band_width': 0.2, 'volume_confirmation': 0.2, 'trend_alignment': 0.15, 'volatility_adjustment': 0.1},
        'momentum_rotation': {'momentum_strength': 0.3, 'relative_strength': 0.25, 'volume_confirmation': 0.2, 'trend_alignment': 0.15, 'volatility_adjustment': 0.1},
        'turtle_enhanced': {'breakout_quality': 0.3, 'trend_confirmation': 0.25, 'volatility_adjustment': 0.2, 'volume_confirmation': 0.15, 'position_sizing': 0.1}
    }
    
    factors = strategy_factors.get(strategy_name, {'default': 1.0})
    
    # ä¸ºæ¯ä¸ªä¿¡å·è®¡ç®—å¼ºåº¦
    enhanced_signals = []
    for signal in signals:
        if signal['type'] != 'buy':
            enhanced_signals.append(signal)
            continue
            
        signal_date = signal['date']
        signal_idx = df[df['date'] == signal_date].index
        if len(signal_idx) == 0:
            enhanced_signals.append(signal)
            continue
            
        idx = signal_idx[0]
        if idx < 20:
            enhanced_signals.append(signal)
            continue
            
        current_row = df.iloc[idx]
        prev_row = df.iloc[idx-1] if idx > 0 else current_row
        
        # è®¡ç®—å„å› å­å¾—åˆ† (0-100åˆ†)
        factor_scores = {}
        
        if strategy_name == 'deep_fusion':
            # MAå¯¹é½åº¦
            ma_score = 0
            if current_row['ma5'] > current_row['ma20'] > current_row['ma60']:
                ma_score = 100
            elif current_row['ma5'] > current_row['ma20']:
                ma_score = 70
            elif current_row['ma5'] < current_row['ma20'] < current_row['ma60']:
                ma_score = 30
            else:
                ma_score = 50
            factor_scores['ma_alignment'] = ma_score * base_weight['trend']
            
            # MACDåŠ¨é‡
            macd_score = 0
            if current_row['macd'] > 0 and current_row['macd'] > prev_row['macd']:
                macd_score = 100
            elif current_row['macd'] > 0:
                macd_score = 70
            elif current_row['macd'] < 0 and current_row['macd'] < prev_row['macd']:
                macd_score = 30
            else:
                macd_score = 50
            factor_scores['macd_momentum'] = macd_score * base_weight['momentum']
            
            # RSIæ¡ä»¶
            rsi_score = 0
            if current_row['rsi'] < 25:
                rsi_score = 100
            elif current_row['rsi'] < 35:
                rsi_score = 80
            elif current_row['rsi'] < 45:
                rsi_score = 60
            elif current_row['rsi'] > 70:
                rsi_score = 20
            else:
                rsi_score = 50
            factor_scores['rsi_condition'] = rsi_score * base_weight['volatility']
            
            # æˆäº¤é‡ç¡®è®¤
            vol_score = 0
            if current_row['volume'] > current_row['volMa5'] * 2:
                vol_score = 100
            elif current_row['volume'] > current_row['volMa5'] * 1.5:
                vol_score = 80
            elif current_row['volume'] > current_row['volMa5']:
                vol_score = 60
            else:
                vol_score = 40
            factor_scores['volume_confirmation'] = vol_score
            
            # å¸ƒæ—å¸¦ä½ç½®
            boll_score = 0
            if current_row['close'] < current_row['bollDown']:
                boll_score = 100
            elif current_row['close'] < current_row['bollMid']:
                boll_score = 70
            elif current_row['close'] > current_row['bollUp']:
                boll_score = 30
            else:
                boll_score = 50
            factor_scores['bollinger_position'] = boll_score
            
            # ä»·æ ¼åŠ¨é‡
            momentum_score = 0
            price_change_5d = (current_row['close'] - df.iloc[max(0, idx-5)]['close']) / df.iloc[max(0, idx-5)]['close'] * 100
            if price_change_5d > 5:
                momentum_score = 80
            elif price_change_5d > 2:
                momentum_score = 60
            elif price_change_5d < -5:
                momentum_score = 30
            else:
                momentum_score = 50
            factor_scores['price_momentum'] = momentum_score * base_weight['momentum']
            
            # æ³¢åŠ¨ç‡è°ƒæ•´
            vol_adj_score = 100
            if current_row['atr_pct'] > 5:
                vol_adj_score = 70
            elif current_row['atr_pct'] > 3:
                vol_adj_score = 85
            factor_scores['volatility_adjustment'] = vol_adj_score * base_weight['volatility']
            
        elif strategy_name == 'volume_breakout':
            # çªç ´å¼ºåº¦
            breakout_score = 0
            if current_row['close'] > current_row['high20']:
                breakout_score = 100
            elif current_row['close'] > current_row['high10']:
                breakout_score = 80
            elif current_row['close'] > current_row['high60']:
                breakout_score = 60
            else:
                breakout_score = 40
            factor_scores['breakout_strength'] = breakout_score * base_weight['momentum']
            
            # æˆäº¤é‡æ¿€å¢
            vol_surge_score = 0
            vol_ratio = current_row['volume'] / current_row['volMa5']
            if vol_ratio > 3:
                vol_surge_score = 100
            elif vol_ratio > 2:
                vol_surge_score = 85
            elif vol_ratio > 1.5:
                vol_surge_score = 70
            else:
                vol_surge_score = 50
            factor_scores['volume_surge'] = vol_surge_score
            
            # è¶‹åŠ¿å¯¹é½
            trend_align_score = 0
            if current_row['ma5'] > current_row['ma20'] > current_row['ma60']:
                trend_align_score = 100
            elif current_row['ma5'] > current_row['ma20']:
                trend_align_score = 75
            elif current_row['ma5'] < current_row['ma20']:
                trend_align_score = 40
            else:
                trend_align_score = 60
            factor_scores['trend_alignment'] = trend_align_score * base_weight['trend']
            
            # æ³¢åŠ¨ç‡è¿‡æ»¤
            vol_filter_score = 100
            if current_row['bollWidth'] < 0.05:  # å¸ƒæ—å¸¦è¿‡çª„ï¼Œçªç ´å¯èƒ½æ— æ•ˆ
                vol_filter_score = 40
            elif current_row['bollWidth'] > 0.2:  # æ³¢åŠ¨è¿‡å¤§ï¼Œé£é™©é«˜
                vol_filter_score = 60
            factor_scores['volatility_filter'] = vol_filter_score * base_weight['volatility']
            
        # å…¶ä»–ç­–ç•¥çš„ä¿¡å·å¼ºåº¦è®¡ç®—å¯ä»¥ç±»ä¼¼å®ç°...
        # ä¸ºäº†ç®€æ´ï¼Œè¿™é‡Œå…ˆå®ç°ä¸¤ä¸ªä¸»è¦ç­–ç•¥ï¼Œå…¶ä»–ç­–ç•¥ä½¿ç”¨åŸºç¡€è¯„åˆ†
        
        else:
            # é»˜è®¤ä¿¡å·å¼ºåº¦è®¡ç®—
            base_strength = signal.get('strength', 50)
            factor_scores['default'] = base_strength
        
        # è®¡ç®—ç»¼åˆå¼ºåº¦
        total_score = 0
        total_weight = 0
        
        for factor, weight in factors.items():
            score = factor_scores.get(factor, 50)
            total_score += score * weight
            total_weight += weight
        
        if total_weight > 0:
            final_strength = min(100, max(20, total_score / total_weight))
        else:
            final_strength = signal.get('strength', 50)
        
        # æ›´æ–°ä¿¡å·å¼ºåº¦
        enhanced_signal = signal.copy()
        enhanced_signal['strength'] = final_strength
        enhanced_signals.append(enhanced_signal)
    
    return enhanced_signals





def calculate_chip_distribution(df, window=360, date=None):
    """è®¡ç®—ç­¹ç åˆ†å¸ƒ"""
    if df is None or len(df) == 0:
        return []
    
    # è½¬æ¢ä¸ºDataFrameï¼ˆå¦‚æœæ˜¯å­—å…¸åˆ—è¡¨ï¼‰
    if isinstance(df, list):
        df = pd.DataFrame(df)
    
    # å¦‚æœæŒ‡å®šäº†æ—¥æœŸï¼Œæ‰¾åˆ°è¯¥æ—¥æœŸçš„æ•°æ®
    if date:
        df['date'] = pd.to_datetime(df['date'])
        target_date = pd.to_datetime(date)
        
        # æ‰¾åˆ°æœ€æ¥è¿‘çš„æ—¥æœŸ
        if target_date in df['date'].values:
            df = df[df['date'] <= target_date]
        else:
            # æ‰¾åˆ°æœ€æ¥è¿‘çš„æ—¥æœŸ
            closest_idx = (df['date'] - target_date).abs().idxmin()
            df = df.iloc[:closest_idx + 1]
    
    # ä½¿ç”¨æœ€è¿‘windowå¤©çš„æ•°æ®
    df = df.tail(window)
    
    if len(df) < 10:
        return []
    
    # è®¡ç®—ä»·æ ¼åŒºé—´
    min_price = df['low'].min()
    max_price = df['high'].max()
    
    if min_price == max_price:
        return []
    
    # åˆ†æˆ20ä¸ªä»·æ ¼åŒºé—´
    num_bins = 120
    price_bins = np.linspace(min_price, max_price, num_bins + 1)
    bin_centers = (price_bins[:-1] + price_bins[1:]) / 2
    chip_volumes = np.zeros(num_bins, dtype=float)
    
    if 'date' in df.columns:
        df = df.copy()
        try:
            df['date'] = pd.to_datetime(df['date'])
            df = df.sort_values('date')
        except Exception:
            pass
    
    vol_ema = None
    for _, row in df.iterrows():
        day_low = float(row.get('low', np.nan))
        day_high = float(row.get('high', np.nan))
        day_volume = float(row.get('volume', 0) or 0)
        day_close = float(row.get('close', np.nan))
        
        if not np.isfinite(day_low) or not np.isfinite(day_high):
            continue
        
        if day_high < day_low:
            day_low, day_high = day_high, day_low

        if np.isfinite(day_volume) and day_volume > 0:
            vol_ema = day_volume if vol_ema is None else (vol_ema * 0.9 + day_volume * 0.1)
        
        turnover = row.get('turnover')
        # ä¸¥æ ¼æ£€æŸ¥ turnover æ˜¯å¦ä¸ºæœ‰æ•ˆæ•°å­—
        turnover_valid = False
        try:
            if pd.notna(turnover) and str(turnover).strip() != '':
                turnover_val = float(turnover)
                if 0 < turnover_val <= 100:
                    turnover_valid = True
                    turnover = turnover_val
        except (ValueError, TypeError):
            pass

        if turnover_valid:
            turnover_ratio = turnover / 100
        elif vol_ema and np.isfinite(day_volume) and day_volume > 0:
            turnover_ratio = 0.01 * (day_volume / vol_ema)
        else:
            turnover_ratio = 0.01
        turnover_ratio = min(max(turnover_ratio, 0.002), 0.08)
        daily_retain = 1 - min(max(turnover_ratio, 0.001), 1)
        chip_volumes *= daily_retain
        
        if day_high == day_low:
            bin_idx = np.searchsorted(price_bins, day_high, side='right') - 1
            if 0 <= bin_idx < num_bins:
                chip_volumes[bin_idx] += turnover_ratio
            continue
        
        if np.isfinite(day_close):
            typical_price = (day_high + day_low + day_close) / 3
        else:
            typical_price = (day_high + day_low) / 2
        
        range_width = day_high - day_low
        sigma = max(range_width / 20, typical_price * 0.002)
        
        if sigma <= 0:
            bin_idx = np.searchsorted(price_bins, typical_price, side='right') - 1
            if 0 <= bin_idx < num_bins:
                chip_volumes[bin_idx] += turnover_ratio
            continue
        
        z = (bin_centers - typical_price) / sigma
        weights = np.exp(-0.5 * z * z)
        weights[(bin_centers < day_low) | (bin_centers > day_high)] = 0
        weights[np.abs(z) > 2.5] = 0
        
        total_w = weights.sum()
        if total_w <= 0:
            continue
        
        chip_volumes += (weights / total_w) * turnover_ratio
    
    total_volume = chip_volumes.sum()
    if total_volume <= 0:
        return []
    
    chip_distribution = []
    for i, price in enumerate(bin_centers):
        volume_in_range = chip_volumes[i]
        concentration = (volume_in_range / total_volume * 100) if total_volume > 0 else 0
        chip_distribution.append({
            'price': round(price, 2),
            'volume': round(float(volume_in_range), 6),
            'concentration': round(concentration, 2)
        })
    
    return chip_distribution


# APIè·¯ç”±
@app.route('/api/local_state', methods=['GET'])
def api_get_local_state():
    key = (request.args.get('key') or '').strip()
    if key not in _ALLOWED_LOCAL_STATE_KEYS:
        return jsonify({'success': False, 'message': 'key ä¸å…è®¸'}), 400
    value = _read_local_state_value(key)
    return jsonify({'success': True, 'key': key, 'value': value})


@app.route('/api/local_state', methods=['POST'])
def api_set_local_state():
    payload = request.get_json(silent=True) or {}
    key = (payload.get('key') or '').strip()
    if key not in _ALLOWED_LOCAL_STATE_KEYS:
        return jsonify({'success': False, 'message': 'key ä¸å…è®¸'}), 400
    value = payload.get('value', None)
    ok = _write_local_state_value(key, value)
    return jsonify({'success': ok, 'key': key})


@app.route('/api/stock_data', methods=['GET'])
def api_get_stock_data():
    """è·å–è‚¡ç¥¨æ•°æ®ï¼ˆå¸¦ç¼“å­˜ï¼‰ï¼Œæ”¯æŒæ—¥çº¿/å‘¨çº¿/æœˆçº¿"""
    ts_code = request.args.get('ts_code', '000001.SZ')
    start_date = request.args.get('start_date', '2022-01-01')
    end_date = request.args.get('end_date', datetime.now().strftime('%Y-%m-%d'))
    freq = request.args.get('freq', 'D').upper()  # D=æ—¥çº¿, W=å‘¨çº¿, M=æœˆçº¿
    
    # éªŒè¯ freq å‚æ•°
    if freq not in ['D', 'W', 'M']:
        freq = 'D'
    
    print(f"APIè¯·æ±‚: ts_code={ts_code}, start_date={start_date}, end_date={end_date}, freq={freq}")
    
    # ä½¿ç”¨ç¼“å­˜ç®¡ç†å™¨è·å–æ•°æ®
    data = cache_manager.get_stock_data(ts_code, start_date, end_date, freq)
    print(f"ä»ç¼“å­˜ç®¡ç†å™¨è·å–æ•°æ®ç»“æœ: {type(data)}, é•¿åº¦: {len(data) if data else 'None'}")
    
    if data is None or (isinstance(data, list) and len(data) == 0):
        # å¦‚æœæ— æ³•è·å–çœŸå®æ•°æ®ï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        print(f"çœŸå®æ•°æ®è·å–å¤±è´¥ï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®: {ts_code}")
        data = TushareDataFetcher.gen_mock_data(ts_code, start_date, end_date)
        
        if data is None or len(data) == 0:
            return jsonify({
                'success': False,
                'message': f'æ— æ³•è·å–è‚¡ç¥¨æ•°æ®: {ts_code}',
                'data': []
            })
    
    # è½¬æ¢ä¸ºDataFrameï¼ˆå¦‚æœæ˜¯å­—å…¸åˆ—è¡¨ï¼‰
    if isinstance(data, list):
        df = pd.DataFrame(data)
    else:
        df = data
    
    # è¡¥å…¨ç¼ºå¤±çš„æ¢æ‰‹ç‡ï¼ˆä½¿ç”¨æˆäº¤é‡ä¼°ç®—ï¼‰
    # df = fill_missing_turnover_with_volume(df)

    # è®¡ç®—æŒ‡æ ‡
    df = calculate_indicators(df)
    
    # è¯†åˆ«å¸‚åœºçŠ¶æ€
    market_state = identify_market_state(df)
    
    # è®¡ç®—ç­¹ç åˆ†å¸ƒ
    chip_data = calculate_chip_distribution(df)
    
    # è½¬æ¢ä¸ºJSON
    data = df.to_dict(orient='records')
    for row in data:
        for key, value in row.items():
            if pd.isna(value):
                row[key] = None
    
    # æ ¹æ®å‘¨æœŸè¿”å›å¯¹åº”çš„å‘¨æœŸæ ‡è¯†
    freq_name = {'D': 'daily', 'W': 'weekly', 'M': 'monthly'}.get(freq, 'daily')
    
    return jsonify({
        'success': True,
        'message': 'ok',
        'ts_code': ts_code,
        'freq': freq,
        'freq_name': freq_name,
        'market_state': market_state,
        'data_count': len(data),
        'data': data,
        'chip_distribution': chip_data,
        'cached': True
    })


@app.route('/api/index_stocks', methods=['GET'])
def api_get_index_stocks():
    """è·å–æŒ‡æ•°æˆåˆ†è‚¡"""
    index_code = request.args.get('index_code', '000300.SH')
    
    # æ£€æŸ¥ç¼“å­˜
    cache_key = f'index_stocks_{index_code}'
    cached = cache_manager.get('params', cache_key)
    if cached:
        cached_at = datetime.fromisoformat(cached['meta']['cached_at'])
        if (datetime.now() - cached_at).days < 7: # ç¼“å­˜7å¤©
            cached_data = cached.get('data')
            expected = 50 if index_code == '000016.SH' else (300 if index_code == '000300.SH' else None)
            if expected and isinstance(cached_data, list) and len(cached_data) < max(10, expected // 2):
                cached_data = None
            if cached_data is not None:
                return jsonify({'success': True, 'count': len(cached_data) if isinstance(cached_data, list) else 0, 'data': cached_data})
            
    data = TushareDataFetcher.get_index_weights(index_code)
    
    # å¦‚æœè·å–å¤±è´¥ï¼Œè¿”å›ä¸€äº›æ¨¡æ‹Ÿæ•°æ®ä½œä¸º fallback
    if not data:
        if index_code == '000016.SH': # ä¸Šè¯50
            data = [
                {'ts_code': '600519.SH', 'name': 'è´µå·èŒ…å°'}, {'ts_code': '601318.SH', 'name': 'ä¸­å›½å¹³å®‰'},
                {'ts_code': '600036.SH', 'name': 'æ‹›å•†é“¶è¡Œ'}, {'ts_code': '600276.SH', 'name': 'æ’ç‘åŒ»è¯'},
                {'ts_code': '600030.SH', 'name': 'ä¸­ä¿¡è¯åˆ¸'}, {'ts_code': '601012.SH', 'name': 'éš†åŸºç»¿èƒ½'}
            ]
        elif index_code == '000300.SH': # æ²ªæ·±300
             data = [
                {'ts_code': '600519.SH', 'name': 'è´µå·èŒ…å°'}, {'ts_code': '300750.SZ', 'name': 'å®å¾·æ—¶ä»£'},
                {'ts_code': '000858.SZ', 'name': 'äº”ç²®æ¶²'}, {'ts_code': '002594.SZ', 'name': 'æ¯”äºšè¿ª'},
             ]
             
    if data:
        cache_manager.set('params', cache_key, data)
        
    return jsonify({'success': True, 'count': len(data) if data else 0, 'data': data})


@app.route('/api/stock_list', methods=['GET'])
def api_get_stock_list():
    """è·å–è‚¡ç¥¨åˆ—è¡¨ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    file_cached = _load_json_cache_file(STOCK_LIST_CACHE_FILE)
    if file_cached:
        try:
            cached_at = datetime.fromisoformat(file_cached['cached_at'])
            if (datetime.now() - cached_at).days < 30 and len(file_cached['data']) >= 2000:
                return jsonify({
                    'success': True,
                    'count': len(file_cached['data']),
                    'data': file_cached['data'],
                    'cached': True
                })
        except Exception:
            pass

    cache_key = 'stock_list'
    cached = cache_manager.get('params', cache_key)
    
    if cached:
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¶…è¿‡7å¤©
        cached_at = datetime.fromisoformat(cached['meta']['cached_at'])
        if (datetime.now() - cached_at).days < 7:
            print("[ç¼“å­˜å‘½ä¸­] è‚¡ç¥¨åˆ—è¡¨")
            return jsonify({
                'success': True,
                'count': len(cached['data']),
                'data': cached['data'],
                'cached': True
            })
    
    pro_client = _get_pro()
    if pro_client is None:
        default_stocks = [
            {'ts_code': '000001.SZ', 'symbol': '000001', 'name': 'å¹³å®‰é“¶è¡Œ', 'industry': 'é“¶è¡Œ'},
            {'ts_code': '000002.SZ', 'symbol': '000002', 'name': 'ä¸‡ç§‘A', 'industry': 'æˆ¿åœ°äº§'},
            {'ts_code': '600519.SH', 'symbol': '600519', 'name': 'è´µå·èŒ…å°', 'industry': 'ç™½é…’'},
            {'ts_code': '000858.SZ', 'symbol': '000858', 'name': 'äº”ç²®æ¶²', 'industry': 'ç™½é…’'},
            {'ts_code': '601318.SH', 'symbol': '601318', 'name': 'ä¸­å›½å¹³å®‰', 'industry': 'ä¿é™©'},
            {'ts_code': '600036.SH', 'symbol': '600036', 'name': 'æ‹›å•†é“¶è¡Œ', 'industry': 'é“¶è¡Œ'},
            {'ts_code': '000333.SZ', 'name': 'ç¾çš„é›†å›¢', 'industry': 'å®¶ç”µ'},
            {'ts_code': '300750.SZ', 'name': 'å®å¾·æ—¶ä»£', 'industry': 'ç”µæ± '},
        ]
        return jsonify({
            'success': True,
            'count': len(default_stocks),
            'data': default_stocks,
            'cached': False,
            'message': 'æœªé…ç½®Tushare Tokenï¼Œè¡Œä¸š/è‚¡ç¥¨åˆ—è¡¨ä»…æä¾›å°‘é‡é»˜è®¤æ•°æ®ã€‚'
        })

    try:
        # å°è¯•è·å–è‚¡ç¥¨åˆ—è¡¨ï¼Œä¸é™åˆ¶æ•°é‡ä»¥è·å–å…¨é‡è¡Œä¸šä¿¡æ¯
        df = pro_client.stock_basic(
            exchange='',
            list_status='L',
            fields='ts_code,symbol,name,industry'
        )
        
        if df is not None and not df.empty:
            stocks = df.to_dict(orient='records')
            cache_manager.set('params', cache_key, stocks)
            _save_json_cache_file(STOCK_LIST_CACHE_FILE, stocks)
            print(f"[æ›´æ–°ç¼“å­˜] è‚¡ç¥¨åˆ—è¡¨: {len(stocks)} åª")
            return jsonify({
                'success': True,
                'count': len(stocks),
                'data': stocks,
                'cached': False
            })
    except Exception as e:
        print(f"è·å–è‚¡ç¥¨åˆ—è¡¨é”™è¯¯: {e}")
    
    # è¿”å›é»˜è®¤åˆ—è¡¨ï¼ˆå½“APIå¤±è´¥æ—¶ï¼‰
    default_stocks = [
        {'ts_code': '000001.SZ', 'symbol': '000001', 'name': 'å¹³å®‰é“¶è¡Œ', 'industry': 'é“¶è¡Œ'},
        {'ts_code': '000002.SZ', 'symbol': '000002', 'name': 'ä¸‡ç§‘A', 'industry': 'æˆ¿åœ°äº§'},
        {'ts_code': '600519.SH', 'symbol': '600519', 'name': 'è´µå·èŒ…å°', 'industry': 'ç™½é…’'},
        {'ts_code': '000858.SZ', 'symbol': '000858', 'name': 'äº”ç²®æ¶²', 'industry': 'ç™½é…’'},
        {'ts_code': '601318.SH', 'symbol': '601318', 'name': 'ä¸­å›½å¹³å®‰', 'industry': 'ä¿é™©'},
        {'ts_code': '600036.SH', 'symbol': '600036', 'name': 'æ‹›å•†é“¶è¡Œ', 'industry': 'é“¶è¡Œ'},
        {'ts_code': '000333.SZ', 'name': 'ç¾çš„é›†å›¢', 'industry': 'å®¶ç”µ'},
        {'ts_code': '300750.SZ', 'name': 'å®å¾·æ—¶ä»£', 'industry': 'ç”µæ± '},
    ]
    return jsonify({
        'success': True,
        'count': len(default_stocks),
        'data': default_stocks,
        'cached': False,
        'message': 'è‚¡ç¥¨åˆ—è¡¨è·å–å¤±è´¥ï¼Œå·²å›é€€åˆ°å†…ç½®å°‘é‡åˆ—è¡¨ã€‚'
    })


@app.route('/api/concept_list', methods=['GET'])
def api_get_concept_list():
    file_cached = _load_json_cache_file(CONCEPT_LIST_CACHE_FILE)
    if file_cached:
        try:
            cached_at = datetime.fromisoformat(file_cached['cached_at'])
            if (datetime.now() - cached_at).days < 30 and len(file_cached['data']) >= 200:
                return jsonify({'success': True, 'count': len(file_cached['data']), 'data': file_cached['data'], 'cached': True})
        except Exception:
            pass

    pro_client = _get_pro()
    if pro_client is None:
        return jsonify({'success': True, 'count': 0, 'data': [], 'cached': False, 'message': 'æœªé…ç½®Tushare Tokenï¼Œæ— æ³•æ‹‰å–æ¦‚å¿µåˆ—è¡¨ã€‚'})

    try:
        df = None
        try:
            concept_func = getattr(pro_client, 'concept', None)
            if callable(concept_func):
                try:
                    df = concept_func(src='ts')
                except Exception:
                    df = concept_func()
            else:
                try:
                    df = pro_client.query('concept', src='ts')
                except Exception:
                    df = pro_client.query('concept')
        except Exception:
            df = pro_client.query('concept')
        if df is None or df.empty:
            return jsonify({'success': True, 'count': 0, 'data': [], 'cached': False})

        records = df.to_dict(orient='records')
        normalized = []
        for r in records:
            name = r.get('name') or r.get('concept_name') or r.get('ts_name')
            code = r.get('code') or r.get('concept_code') or r.get('ts_code')
            if not name:
                continue
            normalized.append({'name': str(name), 'code': str(code) if code is not None else ''})

        normalized.sort(key=lambda x: x.get('name', ''))
        _save_json_cache_file(CONCEPT_LIST_CACHE_FILE, normalized)
        return jsonify({'success': True, 'count': len(normalized), 'data': normalized, 'cached': False})
    except Exception as e:
        print(f"è·å–æ¦‚å¿µåˆ—è¡¨é”™è¯¯: {e}")
        debug = (request.args.get('debug') or '').strip() == '1'
        payload = {'success': True, 'count': 0, 'data': [], 'cached': False, 'message': 'æ¦‚å¿µåˆ—è¡¨è·å–å¤±è´¥'}
        if debug:
            payload['error'] = str(e)
        return jsonify(payload)


@app.route('/api/concept_members', methods=['GET'])
def api_get_concept_members():
    codes_raw = request.args.get('codes', '') or ''
    codes = [c.strip() for c in codes_raw.split(',') if c.strip()]
    if not codes:
        return jsonify({'success': False, 'message': 'codes ä¸èƒ½ä¸ºç©º', 'ts_codes': [], 'count': 0}), 400

    pro_client = _get_pro()
    if pro_client is None:
        return jsonify({'success': True, 'message': 'æœªé…ç½®Tushare Tokenï¼Œæ— æ³•æ‹‰å–æ¦‚å¿µæˆåˆ†è‚¡ã€‚', 'ts_codes': [], 'count': 0, 'cached': False})

    all_ts_codes = set()
    by_code = {}
    any_cached = False

    for concept_code in codes[:50]:
        cache_file = os.path.join(CONCEPT_MEMBERS_CACHE_DIR, f"{concept_code}.json")
        file_cached = _load_json_cache_file(cache_file)
        if file_cached:
            try:
                cached_at = datetime.fromisoformat(file_cached['cached_at'])
                if (datetime.now() - cached_at).days < 30 and len(file_cached['data']) >= 1:
                    members = file_cached['data']
                    by_code[concept_code] = members
                    for ts in members:
                        all_ts_codes.add(ts)
                    any_cached = True
                    continue
            except Exception:
                pass

        try:
            df = None
            try:
                detail_func = getattr(pro_client, 'concept_detail', None)
                if callable(detail_func):
                    try:
                        df = detail_func(id=concept_code)
                    except Exception:
                        df = detail_func(concept_id=concept_code)
                else:
                    try:
                        df = pro_client.query('concept_detail', id=concept_code)
                    except Exception:
                        df = pro_client.query('concept_detail', concept_id=concept_code)
            except Exception:
                df = pro_client.query('concept_detail', id=concept_code)
            if df is None or df.empty:
                by_code[concept_code] = []
                continue
            records = df.to_dict(orient='records')
            members = []
            for r in records:
                ts_code = r.get('ts_code') or r.get('con_code')
                if not ts_code:
                    continue
                members.append(str(ts_code))
                all_ts_codes.add(str(ts_code))
            members = sorted(list(set(members)))
            by_code[concept_code] = members
            _save_json_cache_file(cache_file, members)
        except Exception as e:
            print(f"è·å–æ¦‚å¿µæˆåˆ†è‚¡å¤±è´¥: {concept_code} {e}")
            by_code[concept_code] = []

    out = sorted(all_ts_codes)
    return jsonify({'success': True, 'count': len(out), 'ts_codes': out, 'by_code': by_code, 'cached': any_cached})


@app.route('/api/best_strategy', methods=['POST'])
def api_best_strategy():
    payload = request.get_json(silent=True) or {}

    ts_codes = payload.get('ts_codes') or []
    if not isinstance(ts_codes, list) or len(ts_codes) == 0:
        return jsonify({'success': False, 'message': 'ts_codes ä¸èƒ½ä¸ºç©ºä¸”å¿…é¡»ä¸ºæ•°ç»„', 'data': []}), 400

    if len(ts_codes) > 300:
        ts_codes = ts_codes[:300]

    start_date = payload.get('start_date', '2022-01-01')
    end_date = payload.get('end_date', datetime.now().strftime('%Y-%m-%d'))
    signal_period = int(payload.get('signal_period', 3))
    history_window = int(payload.get('history_window', 180))
    init_capital = float(payload.get('init_capital', 1000000))

    strategies = payload.get('strategies') or list(StrategyEngine.STRATEGIES.keys())
    if not isinstance(strategies, list) or len(strategies) == 0:
        strategies = list(StrategyEngine.STRATEGIES.keys())

    base_config = payload.get('config') or {}
    if not isinstance(base_config, dict):
        base_config = {}

    results = []

    for ts_code in ts_codes:
        try:
            data = cache_manager.get_stock_data(ts_code, start_date, end_date) or []
            if not data or len(data) < 80:
                mock = TushareDataFetcher.gen_mock_data(ts_code, start_date, end_date)
                if mock and len(mock) >= 80:
                    data = mock
                else:
                    continue

            df = pd.DataFrame(data)
            df = calculate_indicators(df)
            records = df.where(pd.notnull(df), None).to_dict('records')
            if not records:
                continue

            last_date_str = records[-1].get('date')
            if not last_date_str:
                continue

            last_dt = datetime.strptime(last_date_str, '%Y-%m-%d')
            recent_cutoff = last_dt - timedelta(days=signal_period)
            history_start = last_dt - timedelta(days=history_window)

            history_records = [
                r for r in records
                if r.get('date') and history_start <= datetime.strptime(r['date'], '%Y-%m-%d') <= recent_cutoff
            ]

            best = None

            for strategy in strategies:
                config = {**base_config}
                if 'takeProfit' not in config:
                    config['takeProfit'] = 0.15
                if 'stopLoss' not in config:
                    config['stopLoss'] = 0.08
                if 'volumeMulti' not in config:
                    config['volumeMulti'] = 1.5

                signals = StrategyEngine.execute_strategy(records, strategy, config)
                if not signals:
                    continue

                recent_buys = [
                    s for s in signals
                    if s.get('type') == 'buy' and s.get('date') and datetime.strptime(s['date'], '%Y-%m-%d') >= recent_cutoff
                ]
                if not recent_buys:
                    continue

                recent_buy_date = max(s['date'] for s in recent_buys if s.get('date'))

                hist_score = 0
                hist_return = 0
                hist_win_rate = 0
                hist_trade_count = 0

                if len(history_records) >= 80:
                    hist_signals = StrategyEngine.execute_strategy(history_records, strategy, config)
                    hist_res = StrategyEngine.calculate_backtest(history_records, hist_signals, init_capital)
                    hist_score = float(hist_res.get('score') or 0)
                    hist_return = float(hist_res.get('totalReturn') or 0)
                    hist_win_rate = float(hist_res.get('winRate') or 0)
                    hist_trade_count = int(hist_res.get('tradeCount') or 0)

                cand = {
                    'ts_code': ts_code,
                    'best_strategy': strategy,
                    'recent_buy_date': recent_buy_date,
                    'history_score': hist_score,
                    'history_return': hist_return,
                    'history_win_rate': hist_win_rate,
                    'history_trade_count': hist_trade_count
                }

                if best is None or cand['history_score'] > best['history_score'] or (
                    cand['history_score'] == best['history_score'] and cand['history_return'] > best['history_return']
                ):
                    best = cand

            if best is not None:
                meta = StrategyEngine.STRATEGIES.get(best['best_strategy'], {})
                best['best_strategy_name'] = meta.get('name', best['best_strategy'])
                best['best_strategy_icon'] = meta.get('icon', '')
                results.append(best)
        except Exception as e:
            print(f"best_strategy error: {ts_code} {e}")
            continue

    results.sort(key=lambda x: (x.get('history_score', 0), x.get('history_return', 0)), reverse=True)
    return jsonify({'success': True, 'count': len(results), 'data': results})


# ä»£è¡¨æ€§è‚¡ç¥¨åˆ—è¡¨ï¼ˆæ¯è¡Œä¸š1åªï¼Œç”¨äºæ‰¹é‡å‚æ•°ä¼˜åŒ– - ç²¾ç®€ç‰ˆä»¥æé«˜é€Ÿåº¦ï¼‰
REPRESENTATIVE_STOCKS = {
    'é“¶è¡Œ': ['000001.SZ'],        # å¹³å®‰é“¶è¡Œï¼ˆä½æ³¢åŠ¨ï¼‰
    'ç§‘æŠ€': ['300750.SZ'],        # å®å¾·æ—¶ä»£ï¼ˆé«˜æ³¢åŠ¨ï¼‰
    'åŒ»è¯': ['600276.SH'],        # æ’ç‘åŒ»è¯ï¼ˆä¸­æ³¢åŠ¨ï¼‰
    'ç™½é…’': ['600519.SH'],        # è´µå·èŒ…å°ï¼ˆè¶‹åŠ¿æ€§å¼ºï¼‰
    'æ–°èƒ½æº': ['002594.SZ'],      # æ¯”äºšè¿ªï¼ˆé«˜æ³¢åŠ¨ï¼‰
    'ç”µå­': ['002415.SZ'],        # æµ·åº·å¨è§†ï¼ˆä¸­æ³¢åŠ¨ï¼‰
    'åŒ–å·¥': ['600309.SH'],        # ä¸‡ååŒ–å­¦ï¼ˆå‘¨æœŸè‚¡ï¼‰
    'æœ‰è‰²': ['601899.SH'],        # ç´«é‡‘çŸ¿ä¸šï¼ˆèµ„æºè‚¡ï¼‰
}


class AutoParamOptimizer:
    """è‡ªåŠ¨æ‰¹é‡å‚æ•°ä¼˜åŒ–å™¨"""
    
    @staticmethod
    def get_industry_stocks():
        """è·å–ä»£è¡¨æ€§è‚¡ç¥¨åˆ—è¡¨"""
        stocks = []
        for industry, codes in REPRESENTATIVE_STOCKS.items():
            for code in codes:
                stocks.append({
                    'ts_code': code,
                    'industry': industry
                })
        return stocks
    
    @staticmethod
    def optimize_stock_params(ts_code, industry, start_date, end_date, strategies):
        """å¯¹å•åªè‚¡ç¥¨è¿›è¡Œå…¨ç­–ç•¥å‚æ•°ä¼˜åŒ–"""
        try:
            print(f"å¼€å§‹ä¼˜åŒ– {ts_code} ({industry})...")
            
            # è·å–è‚¡ç¥¨æ•°æ®
            data = cache_manager.get_stock_data(ts_code, start_date, end_date) or []
            print(f"  ä»ç¼“å­˜è·å–æ•°æ®: {len(data)} æ¡")
            
            if not data or len(data) < 30:  # é™ä½æ•°æ®è¦æ±‚
                print(f"  ç¼“å­˜æ•°æ®ä¸è¶³ï¼Œç”Ÿæˆmockæ•°æ®...")
                mock = TushareDataFetcher.gen_mock_data(ts_code, start_date, end_date)
                if mock and len(mock) >= 30:
                    data = mock
                    print(f"  ç”Ÿæˆmockæ•°æ®: {len(data)} æ¡")
                else:
                    print(f"  âŒ æ•°æ®ä¸è¶³ï¼Œè·³è¿‡ {ts_code}")
                    return None
            
            df = pd.DataFrame(data)
            df = calculate_indicators(df)
            
            # åˆ†æè‚¡ç¥¨ç‰¹å¾
            stock_features = StockFeatureAnalyzer.analyze_stock_features(df)
            records = df.where(pd.notnull(df), None).to_dict('records')
            
            results = {}
            
            for strategy in strategies:
                # è·å–è¯¥ç­–ç•¥çš„å‚æ•°ç½‘æ ¼
                param_grid = AutoParamOptimizer.get_param_grid(strategy)
                
                best_result = None
                best_params = None
                best_score = -999
                
                # éå†å‚æ•°ç»„åˆ
                for params in param_grid:
                    config = {**params}
                    
                    # æ‰§è¡Œç­–ç•¥
                    signals = StrategyEngine.execute_strategy(records, strategy, config, stock_features)
                    
                    if signals:
                        result = StrategyEngine.calculate_backtest(records, signals, 1000000)
                        score = result.get('score', 0)
                        
                        if score > best_score:
                            best_score = score
                            best_result = result
                            best_params = params
                
                if best_params:
                    results[strategy] = {
                        'best_params': best_params,
                        'best_result': {
                            'totalReturn': best_result.get('totalReturn', 0),
                            'maxDrawdown': best_result.get('maxDrawdown', 0),
                            'sharpe': best_result.get('sharpe', 0),
                            'winRate': best_result.get('winRate', 0),
                            'score': best_score,
                            'tradeCount': best_result.get('tradeCount', 0)
                        }
                    }
            
            return {
                'ts_code': ts_code,
                'industry': industry,
                'features': stock_features,
                'strategy_results': results
            }
            
        except Exception as e:
            print(f"ä¼˜åŒ–è‚¡ç¥¨å‚æ•°å¤±è´¥ {ts_code}: {e}")
            return None
    
    @staticmethod
    def get_param_grid(strategy):
        """è·å–ç­–ç•¥çš„å‚æ•°ç½‘æ ¼ï¼ˆæ‰©å±•ç‰ˆä»¥æé«˜æ•ˆæœï¼‰"""
        base_params = CrossStockParamOptimizer.UNIVERSAL_PARAMS.get(strategy, {})

        # å®šä¹‰å‚æ•°æœç´¢èŒƒå›´ï¼ˆæ‰©å¤§èŒƒå›´ä»¥æé«˜æ•ˆæœï¼‰
        param_ranges = {
            'takeProfit': [0.08, 0.10, 0.12, 0.15, 0.18, 0.20, 0.25],
            'stopLoss': [0.03, 0.05, 0.06, 0.08, 0.10, 0.12, 0.15],
            'volumeMulti': [1.2, 1.5, 1.8, 2.0, 2.5, 3.0],
        }

        # ç”Ÿæˆå‚æ•°ç»„åˆ
        import itertools
        keys = list(param_ranges.keys())
        values = [param_ranges[k] for k in keys]

        grids = []
        for combo in itertools.product(*values):
            params = dict(zip(keys, combo))
            # æ·»åŠ ç­–ç•¥ç‰¹æœ‰å‚æ•°é»˜è®¤å€¼
            params.update(base_params)
            grids.append(params)

        return grids
    
    @staticmethod
    def build_param_system(optimization_results):
        """æ ¹æ®ä¼˜åŒ–ç»“æœæ„å»ºå‚æ•°ä½“ç³»"""
        industry_params = {}
        
        # æŒ‰è¡Œä¸šå½’ç±»
        for result in optimization_results:
            industry = result['industry']
            features = result['features']
            strategy_results = result['strategy_results']
            
            if industry not in industry_params:
                industry_params[industry] = {
                    'stocks': [],
                    'strategies': {}
                }
            
            industry_params[industry]['stocks'].append({
                'ts_code': result['ts_code'],
                'features': features
            })
            
            # ç´¯åŠ ç­–ç•¥å‚æ•°
            for strategy, data in strategy_results.items():
                if strategy not in industry_params[industry]['strategies']:
                    industry_params[industry]['strategies'][strategy] = {
                        'params_list': [],
                        'scores': []
                    }
                
                industry_params[industry]['strategies'][strategy]['params_list'].append(
                    data['best_params']
                )
                industry_params[industry]['strategies'][strategy]['scores'].append(
                    data['best_result']['score']
                )
        
        # é€‰æ‹©æ¯ä¸ªç­–ç•¥çš„æœ€ä¼˜å‚æ•°ï¼ˆå¾—åˆ†æœ€é«˜çš„é‚£ç»„ï¼‰
        param_system = {}
        for industry, data in industry_params.items():
            param_system[industry] = {}
            
            for strategy, strategy_data in data['strategies'].items():
                params_list = strategy_data['params_list']
                scores = strategy_data['scores']
                
                if not params_list:
                    continue
                
                # æ‰¾åˆ°å¾—åˆ†æœ€é«˜çš„å‚æ•°
                max_score_idx = scores.index(max(scores))
                best_params = params_list[max_score_idx]
                
                param_system[industry][strategy] = best_params
        
        return param_system


# å…¨å±€è¿›åº¦å­˜å‚¨
auto_optimize_progress = {
    'is_running': False,
    'current': 0,
    'total': 0,
    'current_stock': '',
    'results': []
}


@app.route('/api/auto_optimize_params', methods=['POST'])
def api_auto_optimize_params():
    """è‡ªåŠ¨æ‰¹é‡å‚æ•°ä¼˜åŒ–API - å¸¦è¿›åº¦åé¦ˆ"""
    global auto_optimize_progress

    payload = request.get_json(silent=True) or {}

    start_date = payload.get('start_date', '2023-01-01')
    end_date = payload.get('end_date', datetime.now().strftime('%Y-%m-%d'))
    # é»˜è®¤ä¼˜åŒ–æ‰€æœ‰ç­–ç•¥
    all_strategies = list(StrategyEngine.STRATEGIES.keys())
    strategies = payload.get('strategies', all_strategies)

    # è·å–ä»£è¡¨æ€§è‚¡ç¥¨ï¼ˆ8ä¸ªè¡Œä¸šï¼‰
    stocks = AutoParamOptimizer.get_industry_stocks()

    # åˆå§‹åŒ–è¿›åº¦
    auto_optimize_progress = {
        'is_running': True,
        'current': 0,
        'total': len(stocks),
        'current_stock': '',
        'results': []
    }

    print(f"å¼€å§‹è‡ªåŠ¨æ‰¹é‡å‚æ•°ä¼˜åŒ–ï¼Œè‚¡ç¥¨æ•°é‡: {len(stocks)}, ç­–ç•¥: {strategies}")

    optimization_results = []

    for i, stock in enumerate(stocks):
        # æ›´æ–°è¿›åº¦
        auto_optimize_progress['current'] = i + 1
        auto_optimize_progress['current_stock'] = stock['ts_code']

        print(f"ä¼˜åŒ–è¿›åº¦: {i+1}/{len(stocks)} - {stock['ts_code']} ({stock['industry']})")

        try:
            # è°ƒç”¨çœŸå®çš„å‚æ•°ä¼˜åŒ–æ–¹æ³•
            result = AutoParamOptimizer.optimize_stock_params(
                stock['ts_code'],
                stock['industry'],
                start_date,
                end_date,
                strategies
            )

            if result:
                optimization_results.append(result)
                auto_optimize_progress['results'].append(result)
                print(f"  âœ“ {stock['ts_code']} ä¼˜åŒ–æˆåŠŸ")
            else:
                print(f"  âœ— {stock['ts_code']} ä¼˜åŒ–å¤±è´¥ï¼ˆæ— ç»“æœï¼‰")

        except Exception as e:
            print(f"  âœ— {stock['ts_code']} ä¼˜åŒ–å¼‚å¸¸: {e}")
            continue

    print(f"ä¼˜åŒ–å®Œæˆï¼ŒæˆåŠŸ: {len(optimization_results)}/{len(stocks)} åªè‚¡ç¥¨")

    # æ„å»ºå‚æ•°ä½“ç³»
    param_system = AutoParamOptimizer.build_param_system(optimization_results)

    # è½¬æ¢ä¸ºå‰ç«¯éœ€è¦çš„æ ¼å¼ï¼š{strategy: {bestParams: {...}}}
    strategy_params = {}
    for industry, strategies in param_system.items():
        for strategy, params in strategies.items():
            if strategy not in strategy_params:
                strategy_params[strategy] = {
                    'bestParams': params,
                    'industries': {}
                }
            # ä¿å­˜æ¯ä¸ªè¡Œä¸šçš„å‚æ•°
            strategy_params[strategy]['industries'][industry] = params

    # æ ‡è®°å®Œæˆ
    auto_optimize_progress['is_running'] = False

    return jsonify({
        'success': True,
        'message': f'å·²å®Œæˆ{len(optimization_results)}åªè‚¡ç¥¨çš„å‚æ•°ä¼˜åŒ–',
        'optimized_stocks': [r['ts_code'] for r in optimization_results],
        'industries': list(param_system.keys()),
        'param_system': param_system,
        'strategy_params': strategy_params  # å‰ç«¯å¯ä»¥ç›´æ¥ä½¿ç”¨çš„æ ¼å¼
    })


@app.route('/api/auto_optimize_progress', methods=['GET'])
def api_auto_optimize_progress():
    """è·å–è‡ªåŠ¨æ‰¹é‡å‚æ•°ä¼˜åŒ–è¿›åº¦"""
    return jsonify({
        'success': True,
        'is_running': auto_optimize_progress['is_running'],
        'current': auto_optimize_progress['current'],
        'total': auto_optimize_progress['total'],
        'current_stock': auto_optimize_progress['current_stock'],
        'progress_percent': round(auto_optimize_progress['current'] / auto_optimize_progress['total'] * 100, 1) if auto_optimize_progress['total'] > 0 else 0
    })


# é…ç½®æ–‡ä»¶è·¯å¾„
CONFIG_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'config')
CONFIG_FILE = os.path.join(CONFIG_DIR, 'user_config.json')

def ensure_config_dir():
    """ç¡®ä¿é…ç½®ç›®å½•å­˜åœ¨"""
    if not os.path.exists(CONFIG_DIR):
        os.makedirs(CONFIG_DIR)

@app.route('/api/config', methods=['GET'])
def api_get_config():
    """ä»æ–‡ä»¶åŠ è½½ç”¨æˆ·é…ç½®"""
    try:
        ensure_config_dir()
        if os.path.exists(CONFIG_FILE):
            with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                config = json.load(f)
            return jsonify({'success': True, 'config': config})
        else:
            return jsonify({'success': True, 'config': {}})
    except Exception as e:
        return jsonify({'success': False, 'message': str(e)})

@app.route('/api/config', methods=['POST'])
def api_save_config():
    """ä¿å­˜ç”¨æˆ·é…ç½®åˆ°æ–‡ä»¶"""
    try:
        ensure_config_dir()
        config = request.get_json(silent=True) or {}
        with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        return jsonify({'success': True, 'message': 'é…ç½®å·²ä¿å­˜'})
    except Exception as e:
        return jsonify({'success': False, 'message': str(e)})

@app.route('/api/config/export', methods=['GET'])
def api_export_config():
    """å¯¼å‡ºé…ç½®æ–‡ä»¶"""
    try:
        if os.path.exists(CONFIG_FILE):
            return send_file(CONFIG_FILE, as_attachment=True, download_name='quant_config_backup.json')
        else:
            return jsonify({'success': False, 'message': 'é…ç½®æ–‡ä»¶ä¸å­˜åœ¨'})
    except Exception as e:
        return jsonify({'success': False, 'message': str(e)})

@app.route('/api/config/import', methods=['POST'])
def api_import_config():
    """å¯¼å…¥é…ç½®æ–‡ä»¶"""
    try:
        if 'file' not in request.files:
            return jsonify({'success': False, 'message': 'æœªä¸Šä¼ æ–‡ä»¶'})
        file = request.files['file']
        if file.filename == '':
            return jsonify({'success': False, 'message': 'æ–‡ä»¶åä¸ºç©º'})
        
        config = json.load(file)
        ensure_config_dir()
        with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        return jsonify({'success': True, 'message': 'é…ç½®å·²å¯¼å…¥'})
    except Exception as e:
        return jsonify({'success': False, 'message': str(e)})


if __name__ == '__main__':
    print("="*50)
    print("Tushareé‡åŒ–äº¤æ˜“ç³»ç»Ÿåç«¯å¯åŠ¨")
    print("è¯·ç¡®ä¿å·²è®¾ç½®æ­£ç¡®çš„Tushare Token")
    print("è®¿é—®: http://localhost:5000")
    print("="*50)
    app.run(host='0.0.0.0', port=5000, debug=True)
